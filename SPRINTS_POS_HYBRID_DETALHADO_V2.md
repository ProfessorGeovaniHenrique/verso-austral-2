# üöÄ ROADMAP DETALHADO - SISTEMA H√çBRIDO DE ANOTA√á√ÉO POS

**Vers√£o:** 2.0  
**√öltima Atualiza√ß√£o:** 2025-01-15  
**Status Geral:** Sprint 1 Completo (‚úÖ), Sprints 2-6 Pendentes

---

## **VIS√ÉO GERAL DO PROJETO**

### **Objetivo Final**
Construir um sistema de anota√ß√£o POS (Part-of-Speech) em 3 camadas que prioriza conhecimento gramatical interno (VA Grammar), com fallback para spaCy e Gemini, otimizado para **textos ga√∫chos** com cobertura ‚â•95% e custo <$0.005/m√∫sica.

### **Arquitetura em 3 Layers**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  INPUT: Texto bruto (212 palavras)                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  LAYER 1: VA GRAMMAR (Zero-cost, 100% precision)            ‚îÇ
‚îÇ  ‚úÖ 50+ verbos irregulares                                   ‚îÇ
‚îÇ  ‚úÖ Pronomes (6 tipos)                                       ‚îÇ
‚îÇ  ‚úÖ MWEs ga√∫chas (mate amargo, cavalo gateado)              ‚îÇ
‚îÇ  ‚úÖ Heur√≠sticas morfol√≥gicas (-mente, -√ß√£o, -dade)          ‚îÇ
‚îÇ  üìä Cobertura esperada: 60-75%                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
                   (tokens UNKNOWN)
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  LAYER 2: SPACY/STANZA (Fallback para PT-BR geral)          ‚îÇ
‚îÇ  üêç pt_core_news_lg model                                   ‚îÇ
‚îÇ  üìä Cobertura adicional: +20-30%                            ‚îÇ
‚îÇ  üí∞ Custo: Zero (local processing)                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
              (tokens com confidence <90%)
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  LAYER 3: GEMINI FLASH (Fallback IA)                        ‚îÇ
‚îÇ  ü§ñ Zero-shot POS tagging                                   ‚îÇ
‚îÇ  üìä Cobertura adicional: +5-10%                             ‚îÇ
‚îÇ  üí∞ Custo: $0.001-0.005/m√∫sica                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  OUTPUT: Corpus anotado (212 tokens com POS + lema)         ‚îÇ
‚îÇ  üìä Cobertura final esperada: ‚â•95%                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## **SPRINT 0: FUNDA√á√ÉO** ‚úÖ COMPLETO

**Dura√ß√£o:** 2 horas  
**Data:** 2025-01-15  
**Status:** ‚úÖ 100% Implementado

### **Entregas:**
- ‚úÖ `verbal-morphology.ts` - 50+ verbos irregulares
- ‚úÖ `pronoun-system.ts` - Sistema pronominal completo
- ‚úÖ `gaucho-mwe.ts` - 9 templates de MWEs + 15 express√µes fixas
- ‚úÖ `pos-annotation-cache.ts` - Cache inteligente com contexto
- ‚úÖ `hybrid-pos-annotator.ts` - Anotador Layer 1 completo
- ‚úÖ Edge function `annotate-pos` atualizada
- ‚úÖ Testes unit√°rios (15 test cases)
- ‚úÖ Interface de teste visual

### **M√©tricas Alcan√ßadas:**
- Cobertura de conhecimento: 50+ verbos irregulares, 100+ palavras funcionais
- Templates MWE: 9 padr√µes + 15 express√µes fixas
- Cache: expira em 7 dias, m√°ximo 10k entradas

---

## **SPRINT 1: VALIDA√á√ÉO E OTIMIZA√á√ÉO DO LAYER 1** ‚è≥ EM ANDAMENTO

**Dura√ß√£o:** 3-4 horas  
**Status:** 60% completo (infraestrutura pronta, valida√ß√£o pendente)

### **Objetivo:**
Validar que o Layer 1 funciona corretamente, identificar gaps de cobertura e otimizar baseado em dados reais.

### **Fase 1.1: Testes Automatizados** (30 min) ‚è≥
**Tarefas:**
- [ ] Executar test suite completo
- [ ] Validar 15 test cases passando
- [ ] Corrigir falhas se houver
- [ ] Documentar edge cases encontrados

**Comandos:**
```bash
npm run test src/tests/pos-annotator.test.ts
```

**Crit√©rio de sucesso:** 15/15 testes passando

---

### **Fase 1.2: An√°lise de Corpus Real** (60 min) ‚è≥
**Tarefas:**
- [ ] Anotar poema "Quando o Verso Vem Pras Casa" (212 palavras)
- [ ] Anotar 10 letras de m√∫sicas ga√∫chas do corpus (m√©dia 150 palavras cada)
- [ ] Registrar m√©tricas:
  - Taxa de cobertura do Layer 1
  - Palavras desconhecidas mais frequentes (top 20)
  - MWEs n√£o detectadas
  - Errors em lematiza√ß√£o

**Output esperado:**
```
Corpus analisado: 1,712 palavras
Cobertura Layer 1: 68.3%
Palavras UNKNOWN: 542 (31.7%)
Top 20 palavras desconhecidas:
  1. quer√™ncia (23x)
  2. pampa (18x)
  3. coxilha (15x)
  ...
MWEs n√£o detectadas: 8
  - "no lombo do cavalo"
  - "prenda faceira"
  ...
```

**Crit√©rio de sucesso:** Cobertura ‚â•60%

---

### **Fase 1.3: Otimiza√ß√µes Data-Driven** (90 min) ‚è≥
**Tarefas:**

#### **1. Expandir L√©xico VA com palavras ga√∫chas frequentes**
- [ ] Adicionar top 50 substantivos ga√∫chos desconhecidos:
  ```typescript
  // Em hybrid-pos-annotator.ts
  const GAUCHO_NOUNS = new Set([
    'quer√™ncia', 'pampa', 'coxilha', 'galp√£o', 'mate', 'bomba',
    'cuia', 'chimarr√£o', 'prenda', 'pago', 'tropeiro', 'la√ßo',
    'arreio', 'pelego', 'fac√£o', 'churrasco', 'costela', ...
  ]);
  ```

#### **2. Criar templates MWE adicionais**
- [ ] Adicionar padr√µes descobertos na an√°lise:
  ```typescript
  // Em gaucho-mwe.ts
  {
    pattern: 'no lombo [PREP] [NOUN]',
    regex: /\bno lombo\s+(do|da|de)\s+\w+\b/gi,
    pos: 'PREP_PHRASE'
  }
  ```

#### **3. Ajustar heur√≠sticas morfol√≥gicas**
- [ ] Melhorar detec√ß√£o de adjetivos ga√∫chos (-eiro, -a√ßo, -udo)
- [ ] Adicionar padr√µes de diminutivos/aumentativos (-inho, -√£o)

**Crit√©rio de sucesso:** Cobertura sobe para ‚â•75%

---

### **Fase 1.4: Documenta√ß√£o de Findings** (30 min) ‚è≥
- [ ] Criar relat√≥rio `LAYER1_VALIDATION_REPORT.md`
- [ ] Documentar taxa de cobertura final
- [ ] Listar palavras que precisam Layer 2/3
- [ ] Sugerir melhorias para pr√≥ximo sprint

---

## **SPRINT 2: INTEGRA√á√ÉO DO LAYER 2 (SPACY/STANZA)** üêç PR√ìXIMO

**Dura√ß√£o:** 6-8 horas  
**Status:** N√£o iniciado  
**Pr√©-requisito:** Sprint 1 completo com cobertura ‚â•60%

### **Objetivo:**
Integrar processador NLP (spaCy ou Stanza) como fallback para palavras UNKNOWN do Layer 1.

---

### **Fase 2.1: Decis√£o de Tecnologia** (60 min)

#### **Op√ß√£o A: spaCy via Microservi√ßo Python** ‚ö†Ô∏è Complexidade M√©dia
**Pr√≥s:**
- Model maduro e robusto (pt_core_news_lg)
- Alta precis√£o (‚â•92% em PT-BR)
- Documenta√ß√£o extensa

**Contras:**
- Precisa criar microservi√ßo Python separado (Flask/FastAPI)
- Adiciona lat√™ncia de rede (HTTP call)
- Requer deploy separado (Docker container)

**Implementa√ß√£o:**
```python
# spacy-service/app.py
from flask import Flask, request, jsonify
import spacy

nlp = spacy.load('pt_core_news_lg')
app = Flask(__name__)

@app.route('/annotate', methods=['POST'])
def annotate():
    text = request.json['text']
    doc = nlp(text)
    return jsonify([{
        'palavra': token.text,
        'lema': token.lemma_,
        'pos': token.pos_,
        'posDetalhada': token.tag_
    } for token in doc])
```

**Custo:** Zero (processing local), mas requer infraestrutura adicional

---

#### **Op√ß√£o B: Stanza.js (Node.js nativo)** ‚úÖ RECOMENDADO
**Pr√≥s:**
- Roda nativamente em Node.js (sem Python)
- Integra√ß√£o direta com Deno edge functions
- Model PT-BR dispon√≠vel
- Zero lat√™ncia de rede

**Contras:**
- Menos maduro que spaCy
- Documenta√ß√£o mais limitada
- Precis√£o ligeiramente inferior (~88-90%)

**Implementa√ß√£o:**
```typescript
// supabase/functions/_shared/stanza-annotator.ts
import Stanza from 'stanza';

const nlp = new Stanza.Pipeline('pt', { processors: 'tokenize,pos,lemma' });

export async function annotateWithStanza(text: string) {
  const doc = await nlp.process(text);
  return doc.sentences.flatMap(sent => 
    sent.words.map(word => ({
      palavra: word.text,
      lema: word.lemma,
      pos: mapStanzaToPOS(word.upos),
      confidence: 0.9
    }))
  );
}
```

**Custo:** Zero

---

#### **Op√ß√£o C: Compromise.js (Light NLP)** üöÄ Fallback R√°pido
**Pr√≥s:**
- Extremamente leve (<500kb)
- Zero setup, roda direto no browser/Deno
- Lat√™ncia muito baixa

**Contras:**
- Precis√£o inferior (~75-80%)
- Focado em ingl√™s (PT-BR limitado)
- N√£o recomendado para an√°lise lingu√≠stica rigorosa

**Uso:** Apenas se Op√ß√£o A/B invi√°veis

---

#### **Op√ß√£o D: Pular Layer 2 ‚Üí Gemini direto** ü§ñ Mais Simples
**Pr√≥s:**
- Zero infraestrutura adicional
- Precis√£o alta (‚â•95% com prompt engineering)
- J√° integrado no projeto

**Contras:**
- Custo por token (~$0.002-0.005/m√∫sica)
- Depende de API externa (lat√™ncia, quotas)

**Recomenda√ß√£o:** Usar se Sprint 2 for gargalo no cronograma do MVP

---

### **Decis√£o Recomendada: Op√ß√£o B (Stanza.js)**
**Justificativa:**
- Melhor custo-benef√≠cio (zero custo + integra√ß√£o nativa)
- Cobertura adicional estimada: +25-30%
- Precis√£o adequada (88-90% √© suficiente para fallback)
- Sem complexidade de infraestrutura

---

### **Fase 2.2: Implementa√ß√£o Stanza** (3-4 horas)

#### **Tarefa 2.2.1: Instalar e configurar Stanza.js** (30 min)
```bash
npm install stanza
```

#### **Tarefa 2.2.2: Criar m√≥dulo de anota√ß√£o** (60 min)
**Arquivo:** `supabase/functions/_shared/stanza-annotator.ts`

```typescript
import Stanza from 'stanza';

let nlpPipeline: any = null;

export async function initializeStanza() {
  if (!nlpPipeline) {
    nlpPipeline = new Stanza.Pipeline('pt', {
      processors: 'tokenize,pos,lemma',
      download_method: 'reuse_resources'
    });
  }
  return nlpPipeline;
}

export async function annotateWithStanza(
  words: string[]
): Promise<AnnotatedToken[]> {
  const nlp = await initializeStanza();
  const text = words.join(' ');
  const doc = await nlp.process(text);

  return doc.sentences.flatMap((sent: any, sentIdx: number) =>
    sent.words.map((word: any, wordIdx: number) => ({
      palavra: word.text,
      lema: word.lemma || word.text.toLowerCase(),
      pos: mapStanzaToPOS(word.upos),
      posDetalhada: word.xpos || word.upos,
      features: extractFeatures(word.feats),
      posicao: sentIdx * 100 + wordIdx,
      source: 'stanza' as const,
      confidence: 0.88
    }))
  );
}

function mapStanzaToPOS(upos: string): string {
  const mapping: Record<string, string> = {
    'NOUN': 'NOUN',
    'VERB': 'VERB',
    'ADJ': 'ADJ',
    'ADV': 'ADV',
    'PRON': 'PRON',
    'DET': 'DET',
    'ADP': 'ADP',
    'CCONJ': 'CCONJ',
    'SCONJ': 'SCONJ',
    'NUM': 'NUM',
    'PUNCT': 'PUNCT',
  };
  return mapping[upos] || 'X';
}

function extractFeatures(feats: string | null): Record<string, string> {
  if (!feats) return {};
  
  const features: Record<string, string> = {};
  const pairs = feats.split('|');
  
  for (const pair of pairs) {
    const [key, value] = pair.split('=');
    if (key && value) {
      features[key.toLowerCase()] = value;
    }
  }
  
  return features;
}
```

#### **Tarefa 2.2.3: Integrar no pipeline h√≠brido** (90 min)
**Arquivo:** `supabase/functions/_shared/hybrid-pos-annotator.ts`

```typescript
import { annotateWithStanza } from './stanza-annotator.ts';

export async function annotateWithHybridSystem(
  texto: string,
  enableLayer2: boolean = true
): Promise<AnnotatedToken[]> {
  // Layer 1: VA Grammar
  const layer1Results = await annotateWithVAGrammar(texto);
  
  if (!enableLayer2) {
    return layer1Results;
  }

  // Identificar tokens UNKNOWN
  const unknownTokens = layer1Results.filter(t => t.confidence === 0.0);
  
  if (unknownTokens.length === 0) {
    console.log('‚úÖ Layer 1 cobriu 100% das palavras');
    return layer1Results;
  }

  console.log(`‚ö†Ô∏è ${unknownTokens.length} palavras UNKNOWN, ativando Layer 2 (Stanza)...`);

  // Layer 2: Stanza (apenas para UNKNOWNs)
  const unknownWords = unknownTokens.map(t => t.palavra);
  const stanzaResults = await annotateWithStanza(unknownWords);

  // Merge: substituir UNKNOWNs por anota√ß√µes do Stanza
  const mergedResults = layer1Results.map(token => {
    if (token.confidence > 0) return token; // Manter anota√ß√£o Layer 1
    
    const stanzaMatch = stanzaResults.find(s => s.palavra === token.palavra);
    return stanzaMatch || token;
  });

  const finalStats = calculateVAGrammarCoverage(mergedResults);
  console.log(`‚úÖ Layer 1+2: ${finalStats.coveredByVA}/${finalStats.totalTokens} tokens (${finalStats.coverageRate.toFixed(1)}% cobertura)`);

  return mergedResults;
}
```

#### **Tarefa 2.2.4: Atualizar edge function** (30 min)
**Arquivo:** `supabase/functions/annotate-pos/index.ts`

```typescript
const body = await req.json();
const { text, mode = 'hybrid' } = body;

let annotations;
let stats;

if (mode === 'layer1_only') {
  annotations = await annotateWithVAGrammar(text);
  stats = calculateVAGrammarCoverage(annotations);
} else if (mode === 'hybrid') {
  annotations = await annotateWithHybridSystem(text, true);
  stats = calculateVAGrammarCoverage(annotations);
} else if (mode === 'layer2_only') {
  annotations = await annotateWithStanza(text.split(/\s+/));
  stats = { /* calcular stats */ };
}

return new Response(JSON.stringify({ 
  success: true, 
  annotations, 
  stats,
  mode 
}), ...);
```

#### **Tarefa 2.2.5: Testes de valida√ß√£o** (60 min)
- [ ] Testar modo h√≠brido com texto ga√∫cho
- [ ] Comparar cobertura Layer 1 vs Layer 1+2
- [ ] Validar que palavras UNKNOWN foram anotadas
- [ ] Medir lat√™ncia (deve ser <1s para 200 palavras)

**Crit√©rio de sucesso:** Cobertura ‚â•85% com Layer 1+2

---

### **Fase 2.3: Atualizar Interface de Teste** (30 min)
- [ ] Adicionar dropdown para selecionar modo:
  - Layer 1 Only
  - Layer 1 + 2 (Hybrid)
  - Layer 2 Only (Stanza)
- [ ] Mostrar comparativo de cobertura
- [ ] Adicionar badge de lat√™ncia

---

## **SPRINT 3: INTEGRA√á√ÉO DO LAYER 3 (GEMINI FLASH)** ü§ñ

**Dura√ß√£o:** 4-5 horas  
**Status:** N√£o iniciado  
**Pr√©-requisito:** Sprint 2 completo com cobertura ‚â•85%

### **Objetivo:**
Adicionar Gemini Flash como fallback final para palavras com confidence <90% ap√≥s Layer 2, com cache agressivo para minimizar custo.

---

### **Fase 3.1: Implementar Cliente Gemini** (60 min)

**Arquivo:** `supabase/functions/_shared/gemini-pos-annotator.ts`

```typescript
import { GoogleGenerativeAI } from '@google/generative-ai';

const genAI = new GoogleGenerativeAI(Deno.env.get('GEMINI_API_KEY')!);
const model = genAI.getGenerativeModel({ model: 'gemini-2.5-flash' });

export interface GeminiPOSRequest {
  palavra: string;
  contexto: string; // 3 palavras antes + palavra + 3 palavras depois
}

export async function annotateWithGemini(
  requests: GeminiPOSRequest[]
): Promise<AnnotatedToken[]> {
  // Batch de at√© 50 palavras por request
  const batches = chunkArray(requests, 50);
  const results: AnnotatedToken[] = [];

  for (const batch of batches) {
    const prompt = buildPOSPrompt(batch);
    const response = await model.generateContent(prompt);
    const parsed = parseGeminiResponse(response.response.text());
    results.push(...parsed);
  }

  return results;
}

function buildPOSPrompt(batch: GeminiPOSRequest[]): string {
  return `
Voc√™ √© um anotador lingu√≠stico especializado em portugu√™s brasileiro ga√∫cho.

Tarefa: Para cada palavra abaixo, forne√ßa:
1. POS (Part-of-Speech): NOUN, VERB, ADJ, ADV, PRON, DET, ADP, CCONJ, etc.
2. Lema (forma can√¥nica)
3. Features morfol√≥gicas (g√™nero, n√∫mero, tempo, pessoa, etc.)

Formato de resposta (JSON):
[
  {
    "palavra": "quer√™ncia",
    "lema": "quer√™ncia",
    "pos": "NOUN",
    "features": { "genero": "Fem", "numero": "Sing" }
  }
]

Palavras para anotar:
${batch.map((req, i) => `${i + 1}. "${req.palavra}" no contexto: "${req.contexto}"`).join('\n')}

Responda APENAS com o JSON array, sem markdown.
`;
}

function parseGeminiResponse(text: string): AnnotatedToken[] {
  // Limpar markdown ```json se presente
  const cleaned = text.replace(/```json\n?/g, '').replace(/```\n?/g, '').trim();
  const parsed = JSON.parse(cleaned);

  return parsed.map((item: any, index: number) => ({
    palavra: item.palavra,
    lema: item.lema || item.palavra.toLowerCase(),
    pos: item.pos || 'NOUN',
    posDetalhada: item.pos || 'NOUN',
    features: item.features || {},
    posicao: index,
    source: 'gemini' as const,
    confidence: 0.95
  }));
}

function chunkArray<T>(array: T[], size: number): T[][] {
  const chunks: T[][] = [];
  for (let i = 0; i < array.length; i += size) {
    chunks.push(array.slice(i, i + size));
  }
  return chunks;
}
```

---

### **Fase 3.2: Implementar Cache Persistente** (90 min)

**Arquivo:** Adicionar tabela `pos_annotation_cache` no banco

```sql
CREATE TABLE public.pos_annotation_cache (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  palavra TEXT NOT NULL,
  contexto_hash TEXT NOT NULL,
  lema TEXT NOT NULL,
  pos TEXT NOT NULL,
  pos_detalhada TEXT,
  features JSONB DEFAULT '{}'::jsonb,
  source TEXT NOT NULL, -- 'gemini', 'stanza', 'va_grammar'
  confidence NUMERIC(3,2) DEFAULT 0.95,
  hits_count INTEGER DEFAULT 0,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  last_hit_at TIMESTAMPTZ DEFAULT NOW(),
  expires_at TIMESTAMPTZ DEFAULT (NOW() + INTERVAL '90 days'),
  
  UNIQUE(palavra, contexto_hash)
);

CREATE INDEX idx_pos_cache_lookup ON pos_annotation_cache(palavra, contexto_hash);
CREATE INDEX idx_pos_cache_expires ON pos_annotation_cache(expires_at);
```

**Arquivo:** `supabase/functions/_shared/pos-cache-db.ts`

```typescript
import { SupabaseClient } from '@supabase/supabase-js';

export async function getCachedPOS(
  supabase: SupabaseClient,
  palavra: string,
  contextoHash: string
): Promise<AnnotatedToken | null> {
  const { data, error } = await supabase
    .from('pos_annotation_cache')
    .select('*')
    .eq('palavra', palavra)
    .eq('contexto_hash', contextoHash)
    .gt('expires_at', new Date().toISOString())
    .single();

  if (error || !data) return null;

  // Incrementar contador de hits
  await supabase
    .from('pos_annotation_cache')
    .update({ 
      hits_count: data.hits_count + 1,
      last_hit_at: new Date().toISOString()
    })
    .eq('id', data.id);

  return {
    palavra: data.palavra,
    lema: data.lema,
    pos: data.pos,
    posDetalhada: data.pos_detalhada || data.pos,
    features: data.features as Record<string, string>,
    posicao: 0,
    source: 'cache',
    confidence: data.confidence
  };
}

export async function setCachedPOS(
  supabase: SupabaseClient,
  annotation: AnnotatedToken,
  contextoHash: string
): Promise<void> {
  await supabase
    .from('pos_annotation_cache')
    .upsert({
      palavra: annotation.palavra,
      contexto_hash: contextoHash,
      lema: annotation.lema,
      pos: annotation.pos,
      pos_detalhada: annotation.posDetalhada,
      features: annotation.features,
      source: annotation.source,
      confidence: annotation.confidence,
      hits_count: 0,
      last_hit_at: new Date().toISOString(),
      expires_at: new Date(Date.now() + 90 * 24 * 60 * 60 * 1000).toISOString()
    });
}
```

---

### **Fase 3.3: Integrar Layer 3 no Pipeline** (90 min)

**Arquivo:** `supabase/functions/_shared/hybrid-pos-annotator.ts`

```typescript
export async function annotateWithFullPipeline(
  texto: string,
  supabase: SupabaseClient,
  options: {
    enableLayer2: boolean;
    enableLayer3: boolean;
    geminiThreshold: number; // Confidence m√≠nima antes de chamar Gemini
  } = {
    enableLayer2: true,
    enableLayer3: true,
    geminiThreshold: 0.90
  }
): Promise<AnnotatedToken[]> {
  // Layer 1: VA Grammar
  let results = await annotateWithVAGrammar(texto);
  const layer1Stats = calculateVAGrammarCoverage(results);
  
  console.log(`Layer 1: ${layer1Stats.coverageRate.toFixed(1)}% cobertura`);

  // Layer 2: Stanza (para UNKNOWNs)
  if (options.enableLayer2) {
    const unknowns = results.filter(t => t.confidence === 0.0);
    
    if (unknowns.length > 0) {
      const stanzaResults = await annotateWithStanza(unknowns.map(t => t.palavra));
      results = mergeAnnotations(results, stanzaResults);
      console.log(`Layer 2: +${stanzaResults.length} tokens processados`);
    }
  }

  // Layer 3: Gemini (para low confidence)
  if (options.enableLayer3) {
    const lowConfidence = results.filter(t => t.confidence < options.geminiThreshold);
    
    if (lowConfidence.length > 0) {
      // Verificar cache primeiro
      const cachedPromises = lowConfidence.map(t => 
        getCachedPOS(supabase, t.palavra, createContextHash(texto, t.palavra))
      );
      const cached = await Promise.all(cachedPromises);
      
      const stillUnknown = lowConfidence.filter((t, i) => !cached[i]);
      
      if (stillUnknown.length > 0) {
        console.log(`Layer 3: ${stillUnknown.length} palavras para Gemini`);
        
        const geminiRequests = stillUnknown.map(t => ({
          palavra: t.palavra,
          contexto: extractContext(texto, t.palavra, 3)
        }));
        
        const geminiResults = await annotateWithGemini(geminiRequests);
        
        // Cachear resultados do Gemini
        for (const result of geminiResults) {
          const hash = createContextHash(texto, result.palavra);
          await setCachedPOS(supabase, result, hash);
        }
        
        results = mergeAnnotations(results, geminiResults);
      }
    }
  }

  const finalStats = calculateVAGrammarCoverage(results);
  console.log(`‚úÖ Pipeline completo: ${finalStats.coverageRate.toFixed(1)}% cobertura`);

  return results;
}

function extractContext(texto: string, palavra: string, windowSize: number): string {
  const tokens = texto.split(/\s+/);
  const index = tokens.findIndex(t => t === palavra);
  
  if (index === -1) return palavra;
  
  const start = Math.max(0, index - windowSize);
  const end = Math.min(tokens.length, index + windowSize + 1);
  
  return tokens.slice(start, end).join(' ');
}

function mergeAnnotations(
  base: AnnotatedToken[],
  updates: AnnotatedToken[]
): AnnotatedToken[] {
  return base.map(token => {
    const update = updates.find(u => u.palavra === token.palavra);
    return update || token;
  });
}

function createContextHash(texto: string, palavra: string): string {
  const context = extractContext(texto, palavra, 3);
  // Simple hash (n√£o precisa ser criptogr√°fico)
  let hash = 0;
  for (let i = 0; i < context.length; i++) {
    const char = context.charCodeAt(i);
    hash = ((hash << 5) - hash) + char;
    hash = hash & hash;
  }
  return hash.toString(36);
}
```

---

### **Fase 3.4: Testes e Otimiza√ß√£o** (60 min)
- [ ] Testar pipeline completo (Layer 1 + 2 + 3)
- [ ] Validar cache hit rate (deve ser >70% ap√≥s 10 m√∫sicas)
- [ ] Medir custo Gemini por m√∫sica (target: <$0.005)
- [ ] Otimizar batch size (50 palavras/request)

**Crit√©rio de sucesso:** Cobertura ‚â•95%, custo <$0.005/m√∫sica

---

## **SPRINT 4: DASHBOARD DE MONITORAMENTO** üìä

**Dura√ß√£o:** 3-4 horas  
**Status:** N√£o iniciado  
**Pr√©-requisito:** Sprint 3 completo

### **Objetivo:**
Criar dashboard administrativo para monitorar performance, cobertura e custo do sistema POS em produ√ß√£o.

---

### **Fase 4.1: M√©tricas de Performance** (90 min)

**Criar tabela de m√©tricas:**
```sql
CREATE TABLE public.pos_annotation_metrics (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  date DATE NOT NULL DEFAULT CURRENT_DATE,
  total_words_processed INTEGER DEFAULT 0,
  layer1_coverage_rate NUMERIC(5,2),
  layer2_coverage_rate NUMERIC(5,2),
  layer3_calls INTEGER DEFAULT 0,
  gemini_api_cost_usd NUMERIC(10,6) DEFAULT 0.0,
  cache_hit_rate NUMERIC(5,2),
  avg_processing_time_ms INTEGER,
  
  UNIQUE(date)
);
```

**Edge function logging:**
```typescript
// Em annotate-pos/index.ts
async function logMetrics(stats: any) {
  await supabase.from('pos_annotation_metrics').upsert({
    date: new Date().toISOString().split('T')[0],
    total_words_processed: stats.totalTokens,
    layer1_coverage_rate: stats.layer1Rate,
    layer2_coverage_rate: stats.layer2Rate,
    layer3_calls: stats.geminiCalls,
    gemini_api_cost_usd: stats.geminiCalls * 0.0001, // Estimativa
    cache_hit_rate: stats.cacheHitRate,
    avg_processing_time_ms: stats.processingTime
  });
}
```

---

### **Fase 4.2: Dashboard Visual** (120 min)

**Arquivo:** `src/components/admin/POSMetricsDashboard.tsx`

**Componentes:**
- [ ] **Gr√°fico de Cobertura ao Longo do Tempo** (Recharts Line Chart)
  - Layer 1, Layer 2, Layer 3 empilhados
- [ ] **Distribui√ß√£o de Fontes** (Pie Chart)
  - VA Grammar, Stanza, Gemini, Cache
- [ ] **Custo Acumulado** (Counter)
  - Custo total Gemini API em USD
- [ ] **Cache Hit Rate** (Progress bar)
  - Taxa de cache hits vs. misses
- [ ] **Top 20 Palavras Mais Problem√°ticas** (Table)
  - Palavras que precisam Layer 3 com frequ√™ncia

---

## **SPRINT 5: FEEDBACK LOOP E APRENDIZADO** üîÑ

**Dura√ß√£o:** 3-4 horas  
**Status:** N√£o iniciado  
**Pr√©-requisito:** Sprint 4 completo

### **Objetivo:**
Implementar sistema de valida√ß√£o humana onde usu√°rios/pesquisadores podem corrigir anota√ß√µes POS incorretas, com feedback autom√°tico para melhorar o sistema.

---

### **Fase 5.1: Interface de Valida√ß√£o Humana** (2 horas)

**Arquivo:** `src/components/admin/POSValidationInterface.tsx`

**Funcionalidades:**
- [ ] Mostrar anota√ß√£o atual vs. contexto
- [ ] Permitir editar: POS, lema, features
- [ ] Adicionar justificativa textual
- [ ] Bot√£o "Validar & Salvar"
- [ ] Pr√≥ximo token n√£o validado automaticamente

**Tabela de valida√ß√µes:**
```sql
CREATE TABLE public.pos_human_validations (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  palavra TEXT NOT NULL,
  contexto TEXT NOT NULL,
  pos_original TEXT NOT NULL,
  lema_original TEXT NOT NULL,
  pos_corrigido TEXT NOT NULL,
  lema_corrigido TEXT NOT NULL,
  justificativa TEXT,
  validated_by UUID REFERENCES auth.users(id),
  validated_at TIMESTAMPTZ DEFAULT NOW(),
  applied BOOLEAN DEFAULT FALSE
);
```

---

### **Fase 5.2: Atualiza√ß√£o Autom√°tica do L√©xico** (90 min)

**L√≥gica:**
- Quando valida√ß√£o humana √© salva, verificar se palavra est√° no l√©xico VA
- Se n√£o est√° e foi validada 3+ vezes com mesma corre√ß√£o ‚Üí adicionar ao l√©xico
- Se est√° mas todas as valida√ß√µes corrigem ‚Üí atualizar l√©xico

**Exemplo:**
```typescript
async function applyValidationFeedback() {
  // Buscar valida√ß√µes n√£o aplicadas
  const { data: validations } = await supabase
    .from('pos_human_validations')
    .select('*')
    .eq('applied', false);

  // Agrupar por palavra
  const grouped = groupBy(validations, 'palavra');

  for (const [palavra, validationList] of Object.entries(grouped)) {
    if (validationList.length >= 3) {
      // Consenso: atualizar l√©xico VA
      const mostCommon = findMostCommonCorrection(validationList);
      await addToVALexicon(palavra, mostCommon);
      
      // Marcar valida√ß√µes como aplicadas
      await supabase
        .from('pos_human_validations')
        .update({ applied: true })
        .in('id', validationList.map(v => v.id));
    }
  }
}
```

---

## **SPRINT 6: PRODU√á√ÉO E ESCALABILIDADE** üöÄ

**Dura√ß√£o:** 4-5 horas  
**Status:** N√£o iniciado  
**Pr√©-requisito:** Sprints 1-5 completos

### **Objetivo:**
Otimizar o sistema para processar 30k+ m√∫sicas em modo batch com custo e lat√™ncia m√≠nimos.

---

### **Fase 6.1: Batch Processing Paralelo** (2 horas)

**Arquivo:** `supabase/functions/annotate-corpus-batch/index.ts`

**Estrat√©gia:**
- Processar 100 m√∫sicas em paralelo
- Usar `Promise.allSettled()` para n√£o falhar batch inteiro
- Implementar retry logic para falhas tempor√°rias
- Salvar resultados em `annotated_corpus` table

**C√≥digo:**
```typescript
export async function processMusicBatch(
  songIds: string[],
  supabase: SupabaseClient
): Promise<BatchResult> {
  const BATCH_SIZE = 100;
  const batches = chunkArray(songIds, BATCH_SIZE);
  
  const results = [];
  
  for (const batch of batches) {
    const promises = batch.map(async (songId) => {
      try {
        const { data: song } = await supabase
          .from('music_catalog')
          .select('lyrics')
          .eq('id', songId)
          .single();

        if (!song?.lyrics) return { songId, status: 'skipped' };

        const annotations = await annotateWithFullPipeline(
          song.lyrics,
          supabase,
          { enableLayer2: true, enableLayer3: true, geminiThreshold: 0.90 }
        );

        // Salvar anota√ß√µes
        await saveAnnotations(supabase, songId, annotations);

        return { songId, status: 'success', annotationsCount: annotations.length };
      } catch (error) {
        return { songId, status: 'error', error: error.message };
      }
    });

    const batchResults = await Promise.allSettled(promises);
    results.push(...batchResults);
    
    console.log(`Batch ${results.length / BATCH_SIZE} completo`);
  }

  return {
    total: songIds.length,
    successful: results.filter(r => r.status === 'fulfilled').length,
    failed: results.filter(r => r.status === 'rejected').length
  };
}
```

---

### **Fase 6.2: Otimiza√ß√£o de Custo Gemini** (90 min)

**Estrat√©gias:**

#### **1. Cache Agressivo (70%+ hit rate)**
- Usar `palavra:contexto_hash` como chave
- Expira√ß√£o de 90 dias (vs. 7 dias do cache em mem√≥ria)
- Pr√©-carregar cache com corpus ga√∫cho anotado manualmente

#### **2. Batch Requests (50 palavras/request)**
- Reduzir overhead de API
- Gemini Flash suporta at√© 32k tokens de contexto
- Economiza ~60% em requests

#### **3. Threshold Din√¢mico**
- Iniciar com threshold=0.90 (apenas low confidence)
- Ap√≥s 1000 m√∫sicas anotadas, analisar padr√£o de errors
- Ajustar threshold automaticamente (ex: se Layer 2 tem >95% precis√£o ‚Üí aumentar para 0.95)

#### **4. Fallback Contextual Rules**
- Se palavra aparece 5+ vezes no mesmo documento ‚Üí usar "One Sense Per Text"
- Se palavra tem sufixo conhecido (-mente, -√ß√£o) ‚Üí n√£o chamar Gemini

**Economia esperada:** 50-70% de redu√ß√£o em custos Gemini

---

### **Fase 6.3: Monitoramento de Custo em Tempo Real** (60 min)

**Dashboard de custos:**
```typescript
// src/components/admin/POSCostMonitor.tsx
export const POSCostMonitor = () => {
  const [metrics, setMetrics] = useState(null);

  useEffect(() => {
    fetchMetrics();
  }, []);

  const fetchMetrics = async () => {
    const { data } = await supabase
      .from('pos_annotation_metrics')
      .select('*')
      .order('date', { ascending: false })
      .limit(30);

    const totalCost = data.reduce((sum, d) => sum + d.gemini_api_cost_usd, 0);
    const totalWords = data.reduce((sum, d) => sum + d.total_words_processed, 0);
    const avgCostPerWord = totalCost / totalWords;

    setMetrics({
      totalCost: totalCost.toFixed(4),
      avgCostPerWord: (avgCostPerWord * 1000).toFixed(6), // mili-cents
      totalWords: totalWords.toLocaleString(),
      cacheHitRate: (data[0]?.cache_hit_rate || 0).toFixed(1)
    });
  };

  return (
    <Card>
      <CardHeader>
        <CardTitle>üí∞ Custos de Anota√ß√£o POS</CardTitle>
      </CardHeader>
      <CardContent>
        <div className="grid grid-cols-2 gap-4">
          <div>
            <p className="text-sm text-muted-foreground">Custo Total (30 dias)</p>
            <p className="text-2xl font-bold">${metrics?.totalCost}</p>
          </div>
          <div>
            <p className="text-sm text-muted-foreground">Custo por Palavra</p>
            <p className="text-2xl font-bold">${metrics?.avgCostPerWord}m</p>
          </div>
          <div>
            <p className="text-sm text-muted-foreground">Palavras Processadas</p>
            <p className="text-2xl font-bold">{metrics?.totalWords}</p>
          </div>
          <div>
            <p className="text-sm text-muted-foreground">Cache Hit Rate</p>
            <p className="text-2xl font-bold">{metrics?.cacheHitRate}%</p>
          </div>
        </div>
      </CardContent>
    </Card>
  );
};
```

---

## **RESUMO DAS 6 SPRINTS**

| Sprint | Objetivo | Dura√ß√£o | Status | Entreg√°veis Principais |
|--------|----------|---------|--------|----------------------|
| **0** | Funda√ß√£o Layer 1 | 2h | ‚úÖ Completo | L√©xico VA, MWEs, Cache |
| **1** | Valida√ß√£o Layer 1 | 3-4h | ‚è≥ 60% | Testes, Interface, An√°lise |
| **2** | Integra√ß√£o Layer 2 | 6-8h | ‚ùå N√£o iniciado | Stanza.js, Hybrid Pipeline |
| **3** | Integra√ß√£o Layer 3 | 4-5h | ‚ùå N√£o iniciado | Gemini Flash, Cache DB |
| **4** | Dashboard M√©tricas | 3-4h | ‚ùå N√£o iniciado | Gr√°ficos, Monitoramento |
| **5** | Feedback Loop | 3-4h | ‚ùå N√£o iniciado | Valida√ß√£o Humana |
| **6** | Escalabilidade | 4-5h | ‚ùå N√£o iniciado | Batch Processing |
| **TOTAL** | | **25-34h** | **15% completo** | Sistema H√≠brido Completo |

---

## **M√âTRICAS DE SUCESSO FINAIS**

### **Performance:**
- ‚úÖ Cobertura: ‚â•95% (todas as palavras anotadas)
- ‚úÖ Precis√£o: ‚â•93% (validado por humanos)
- ‚úÖ Lat√™ncia: <5s por m√∫sica (200 palavras)
- ‚úÖ Cache hit rate: ‚â•70% ap√≥s 100 m√∫sicas

### **Economia:**
- ‚úÖ Custo por m√∫sica: <$0.005 USD
- ‚úÖ Layer 1 (zero custo): 60-75% cobertura
- ‚úÖ Layer 2 (zero custo): +20-30% cobertura
- ‚úÖ Layer 3 (paid): apenas 5-10% restante

### **Qualidade:**
- ‚úÖ Zero crashes em produ√ß√£o
- ‚úÖ Fallback gracioso em caso de API failures
- ‚úÖ Feedback loop para melhoria cont√≠nua

---

## **CRONOGRAMA ESTIMADO**

Assumindo **4 horas/dia de trabalho focado**:

- **Semana 1:** Sprint 1 (valida√ß√£o) + in√≠cio Sprint 2
- **Semana 2:** Conclus√£o Sprint 2 + Sprint 3 completo
- **Semana 3:** Sprint 4 + Sprint 5
- **Semana 4:** Sprint 6 + testes finais + documenta√ß√£o

**Total:** 4 semanas para sistema h√≠brido completo em produ√ß√£o

---

## **PR√ìXIMOS PASSOS IMEDIATOS (AGORA)**

### **Tarefa 1: Executar Testes Unit√°rios** (5 min)
```bash
npm run test src/tests/pos-annotator.test.ts
```

### **Tarefa 2: Testar Interface Visual** (10 min)
1. Navegar para Admin ‚Üí Valida√ß√£o de Dom√≠nios ‚Üí üß™ Teste POS Layer 1
2. Selecionar exemplo "üßâ Texto Ga√∫cho"
3. Clicar em "Anotar Texto"
4. Verificar resultados nas 3 abas

### **Tarefa 3: Analisar Cobertura** (15 min)
- Anotar poema completo
- Registrar taxa de cobertura
- Listar palavras UNKNOWN
- Identificar padr√µes nos gaps

### **Tarefa 4: Decis√£o de Prioriza√ß√£o** (5 min)
Com base na cobertura do Layer 1:
- **Se ‚â•75%:** Considerar pular Layer 2 e ir direto para Gemini (Sprint 3)
- **Se 60-75%:** Implementar Layer 2 (Sprint 2)
- **Se <60%:** Expandir l√©xico VA antes de continuar

---

**EXECUTE AS TAREFAS 1-4 AGORA E REPORTE OS RESULTADOS PARA DECIDIR O PR√ìXIMO PASSO** ‚ú®

---

**FIM DO ROADMAP DETALHADO**
