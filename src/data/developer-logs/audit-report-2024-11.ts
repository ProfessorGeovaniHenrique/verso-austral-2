/**
 * üîç RELAT√ìRIO DE AUDITORIA E DEBUGGING - Novembro 2024
 * 
 * Status: CR√çTICO - Otimiza√ß√£o de Recursos Obrigat√≥ria
 * Objetivo: Identificar e corrigir bugs latentes antes de produ√ß√£o
 * Metodologia: An√°lise preventiva priorizando economia de cr√©ditos
 */

export interface BugReport {
  id: string;
  severidade: 'cr√≠tica' | 'alta' | 'm√©dia' | 'baixa';
  categoria: 'seguran√ßa' | 'performance' | 'funcional' | 'ux';
  componente: string;
  arquivo: string;
  linha?: number;
  descri√ß√£o: string;
  impacto: string;
  solu√ß√£o: string;
  esfor√ßo: 'baixo' | 'm√©dio' | 'alto';
  prioridade: number; // 1-5 (1 = mais urgente)
}

export interface RefactoringStrategy {
  fase: number;
  titulo: string;
  objetivos: string[];
  componentes: string[];
  esfor√ßo_total: string;
  economia_cr√©ditos: string;
  prazo_sugerido: string;
}

// ============= FASE 1: BACKEND CR√çTICO =============

export const backendBugs: BugReport[] = [
  {
    id: 'BE-001',
    severidade: 'cr√≠tica',
    categoria: 'seguran√ßa',
    componente: 'annotate-semantic',
    arquivo: 'supabase/functions/annotate-semantic/index.ts',
    linha: 46,
    descri√ß√£o: '‚úÖ RESOLVIDO - User ID hardcoded em produ√ß√£o',
    impacto: 'Todos os jobs s√£o atribu√≠dos ao mesmo usu√°rio fake. RLS policies n√£o funcionam corretamente. Dados n√£o segregados por usu√°rio real.',
    solu√ß√£o: `‚úÖ IMPLEMENTADO em 16/11/2024:
// Autentica√ß√£o JWT real implementada
const authHeader = req.headers.get('authorization');
if (!authHeader) {
  return new Response(JSON.stringify({ error: 'Autentica√ß√£o necess√°ria' }), { 
    status: 401, headers: corsHeaders 
  });
}

const token = authHeader.replace('Bearer ', '');
const { data: { user }, error: authError } = await supabase.auth.getUser(token);

if (authError || !user) {
  return new Response(JSON.stringify({ error: 'Token inv√°lido ou expirado' }), { 
    status: 401, headers: corsHeaders 
  });
}

const userId = user.id; // ‚úÖ User ID real extra√≠do do JWT`,
    esfor√ßo: 'baixo',
    prioridade: 1
  },
  {
    id: 'BE-002',
    severidade: 'cr√≠tica',
    categoria: 'funcional',
    componente: 'process-dialectal-dictionary',
    arquivo: 'supabase/functions/process-dialectal-dictionary/index.ts',
    descri√ß√£o: 'JobId n√£o retornado no response inicial',
    impacto: 'Frontend n√£o consegue rastrear o job criado. UI n√£o mostra progresso correto.',
    solu√ß√£o: `// Ap√≥s inserir job no banco (processInBackground):
return new Response(
  JSON.stringify({ 
    jobId: jobId,
    message: 'Importa√ß√£o iniciada em background',
    estimatedTime: Math.ceil(totalVerbetes / 100) + ' minutos'
  }),
  { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
);`,
    esfor√ßo: 'baixo',
    prioridade: 1
  },
  {
    id: 'BE-003',
    severidade: 'alta',
    categoria: 'performance',
    componente: 'all-dictionary-processors',
    arquivo: 'supabase/functions/process-*-dictionary/index.ts',
    descri√ß√£o: 'Processamento s√≠ncrono sem batching otimizado',
    impacto: 'Timeout em lotes grandes. Edge function pode exceder limite de execu√ß√£o. Custo computacional desnecess√°rio.',
    solu√ß√£o: `// Implementar batching eficiente:
const BATCH_SIZE = 100;
const batches = [];

for (let i = 0; i < entries.length; i += BATCH_SIZE) {
  batches.push(entries.slice(i, i + BATCH_SIZE));
}

for (const batch of batches) {
  const { error: batchError } = await supabase
    .from('dialectal_lexicon')
    .upsert(batch, { 
      onConflict: 'verbete_normalizado',
      ignoreDuplicates: true 
    });
    
  if (batchError) {
    console.error('Batch insert error:', batchError);
    errors += batch.length;
  } else {
    processed += batch.length;
  }
  
  // Atualizar progresso a cada batch
  await supabase
    .from('dictionary_import_jobs')
    .update({ 
      verbetes_processados: processed,
      progresso: Math.round((processed / totalEntries) * 100)
    })
    .eq('id', jobId);
}`,
    esfor√ßo: 'm√©dio',
    prioridade: 2
  },
  {
    id: 'BE-004',
    severidade: 'alta',
    categoria: 'funcional',
    componente: 'all-edge-functions',
    arquivo: 'supabase/functions/*/index.ts',
    descri√ß√£o: '‚úÖ RESOLVIDO - Falta valida√ß√£o de entrada e rate limiting',
    impacto: 'Vulner√°vel a ataques DoS. Dados inv√°lidos podem crashar edge functions. Sem controle de abuso.',
    solu√ß√£o: `‚úÖ IMPLEMENTADO em 16/11/2024:
// Valida√ß√£o de schema implementada em todas as edge functions
interface ProcessRequest {
  fileContent: string;
  volumeNum?: string;
}

function validateRequest(data: any): ProcessRequest {
  if (!data || typeof data !== 'object') {
    throw new Error('Payload inv√°lido');
  }
  
  const { fileContent, volumeNum } = data;
  
  if (!fileContent || typeof fileContent !== 'string') {
    throw new Error('fileContent deve ser uma string v√°lida');
  }
  
  if (fileContent.length > 10000000) {
    throw new Error('fileContent excede tamanho m√°ximo de 10MB');
  }
  
  return { fileContent, volumeNum };
}

// Aplicado em: process-dialectal, process-gutenberg, process-houaiss, process-unesp
// ‚úÖ Batching eficiente (1000 items/batch) implementado
// ‚úÖ Timeout de 50s implementado para prevenir edge function timeout`,
    esfor√ßo: 'm√©dio',
    prioridade: 2
  },
  {
    id: 'BE-005',
    severidade: 'm√©dia',
    categoria: 'performance',
    componente: 'annotate-semantic',
    arquivo: 'supabase/functions/annotate-semantic/index.ts',
    descri√ß√£o: 'Processamento em background sem timeout e controle de recursos',
    impacto: 'Jobs podem rodar indefinidamente. Sem detec√ß√£o de jobs "travados". Desperd√≠cio de recursos computacionais.',
    solu√ß√£o: `// Implementar timeout e monitoramento:
const MAX_PROCESSING_TIME = 30 * 60 * 1000; // 30 minutos
const startTime = Date.now();

async function processWithTimeout() {
  const timeoutPromise = new Promise((_, reject) => 
    setTimeout(() => reject(new Error('Timeout')), MAX_PROCESSING_TIME)
  );
  
  try {
    await Promise.race([
      processCorpusWithAI(jobId, corpus_type, supabaseUrl, supabaseKey),
      timeoutPromise
    ]);
  } catch (error) {
    await supabase
      .from('annotation_jobs')
      .update({ 
        status: 'failed',
        erro_mensagem: 'Job excedeu tempo m√°ximo de processamento (30min)'
      })
      .eq('id', jobId);
  }
}`,
    esfor√ßo: 'm√©dio',
    prioridade: 3
  }
];

// ============= FASE 2: FRONTEND CR√çTICO =============

export const frontendBugs: BugReport[] = [
  {
    id: 'FE-001',
    severidade: 'alta',
    categoria: 'performance',
    componente: 'useAnnotationJobs',
    arquivo: 'src/hooks/useAnnotationJobs.ts',
    linha: 73,
    descri√ß√£o: '‚úÖ RESOLVIDO - Canal Realtime n√£o limpo corretamente no cleanup',
    impacto: 'Memory leak em navega√ß√£o. M√∫ltiplas subscri√ß√µes ativas. Performance degrada ao longo do tempo.',
    solu√ß√£o: `‚úÖ IMPLEMENTADO em 16/11/2024:
// Refs para rastrear estado e channel
const channelRef = useRef<ReturnType<typeof supabase.channel> | null>(null);
const isMountedRef = useRef(true);

const fetchJobs = async () => {
  if (!isMountedRef.current) return; // ‚úÖ Previne updates ap√≥s unmount
  // ... resto do c√≥digo
};

useEffect(() => {
  isMountedRef.current = true;
  fetchJobs();

  channelRef.current = supabase
    .channel('annotation_jobs_changes')
    .on('postgres_changes', { event: '*', schema: 'public', table: 'annotation_jobs' }, 
      () => { fetchJobs(); }
    )
    .subscribe();

  return () => {
    isMountedRef.current = false;
    if (channelRef.current) {
      supabase.removeChannel(channelRef.current); // ‚úÖ Cleanup garantido
      channelRef.current = null;
    }
  };
}, []);`,
    esfor√ßo: 'baixo',
    prioridade: 2
  },
  {
    id: 'FE-002',
    severidade: 'alta',
    categoria: 'performance',
    componente: 'useDictionaryImportJobs',
    arquivo: 'src/hooks/useDictionaryImportJobs.ts',
    linha: 34,
    descri√ß√£o: '‚úÖ RESOLVIDO - Polling infinito mesmo sem jobs ativos',
    impacto: 'Requests desnecess√°rios ao banco. Desperd√≠cio de recursos. Lat√™ncia aumentada.',
    solu√ß√£o: `‚úÖ IMPLEMENTADO em 16/11/2024:
const queryResult = useQuery({
  queryKey: ['dictionary-import-jobs'],
  queryFn: async () => { /* ... */ },
  refetchInterval: (query) => {
    // ‚úÖ Pausar polling quando n√£o h√° jobs ativos
    const hasActiveJobs = query.state.data?.some(
      job => job.status === 'iniciado' || job.status === 'processando' || job.status === 'pendente'
    );
    return hasActiveJobs ? refetchInterval : false;
  },
  staleTime: 1000,
  gcTime: 5 * 60 * 1000, // ‚úÖ Garbage collection configurado
});

// ‚úÖ Realtime subscription com cleanup
const channelRef = useRef<ReturnType<typeof supabase.channel> | null>(null);

useEffect(() => {
  channelRef.current = supabase.channel('dictionary_jobs_realtime')
    .on('postgres_changes', { event: '*', schema: 'public', table: 'dictionary_import_jobs' }, 
      () => { queryResult.refetch(); }
    ).subscribe();

  return () => {
    if (channelRef.current) {
      supabase.removeChannel(channelRef.current);
      channelRef.current = null;
    }
  };
}, []);`,
    esfor√ßo: 'baixo',
    prioridade: 2
  },
  {
    id: 'FE-003',
    severidade: 'm√©dia',
    categoria: 'ux',
    componente: 'DictionaryImportInterface',
    arquivo: 'src/components/advanced/DictionaryImportInterface.tsx',
    linha: 25,
    descri√ß√£o: 'Falta valida√ß√£o se arquivo existe antes de importar',
    impacto: 'Erro gen√©rico sem contexto. UX ruim. Usu√°rio n√£o sabe o que fazer.',
    solu√ß√£o: `// Adicionar valida√ß√£o pr√©via:
const importDialectalVolume = async (volumeNum: 'I' | 'II') => {
  setIsImporting(true);
  
  try {
    const fileName = volumeNum === 'I' 
      ? '/src/data/dictionaries/dialectal-volume-I-raw.txt' 
      : '/src/data/dictionaries/dialectal-volume-II-raw.txt';
    
    // Validar exist√™ncia do arquivo
    const response = await fetch(fileName);
    
    if (!response.ok) {
      if (response.status === 404) {
        toast.error(\`Arquivo n√£o encontrado: Volume \${volumeNum}\`, {
          description: 'Verifique se o arquivo est√° no diret√≥rio correto'
        });
      } else {
        toast.error(\`Erro ao acessar arquivo: \${response.status}\`);
      }
      return;
    }
    
    const rawContent = await response.text();
    
    // Validar conte√∫do n√£o vazio
    if (!rawContent || rawContent.trim().length === 0) {
      toast.error('Arquivo vazio ou inv√°lido');
      return;
    }
    
    // Continuar com processamento...
  } catch (error: any) {
    console.error('Import error:', error);
    toast.error(\`Erro ao iniciar importa√ß√£o\`, {
      description: error.message || 'Erro desconhecido'
    });
  } finally {
    setIsImporting(false);
  }
};`,
    esfor√ßo: 'baixo',
    prioridade: 3
  },
  {
    id: 'FE-004',
    severidade: 'm√©dia',
    categoria: 'funcional',
    componente: 'ValidationInterface',
    arquivo: 'src/components/advanced/ValidationInterface.tsx',
    linha: 35,
    descri√ß√£o: 'Falta valida√ß√£o de campos antes de submit',
    impacto: 'Submit com dados inv√°lidos. Erro no backend. UX ruim.',
    solu√ß√£o: `// Adicionar valida√ß√£o antes de submit:
const handleSubmit = async () => {
  if (!entry) return;
  
  // Validar campos obrigat√≥rios se status √© "incorrect"
  if (status === 'incorrect') {
    if (!tagsetCorrigido) {
      toast.error('Tagset corrigido √© obrigat√≥rio');
      return;
    }
    
    if (!prosodiaCorrigida) {
      toast.error('Pros√≥dia corrigida √© obrigat√≥ria');
      return;
    }
    
    const prosodyValue = parseInt(prosodiaCorrigida);
    if (isNaN(prosodyValue) || prosodyValue < -3 || prosodyValue > 3) {
      toast.error('Pros√≥dia deve estar entre -3 e 3');
      return;
    }
    
    if (!justificativa || justificativa.trim().length < 10) {
      toast.error('Justificativa deve ter ao menos 10 caracteres');
      return;
    }
  }
  
  const success = await submitValidation({
    palavra: entry.palavra,
    tagset_original: entry.tagset_codigo,
    tagset_corrigido: status === 'incorrect' ? tagsetCorrigido : null,
    prosody_original: entry.prosody,
    prosody_corrigida: status === 'incorrect' ? parseInt(prosodiaCorrigida) : null,
    contexto: entry.contexto_exemplo,
    justificativa: status === 'incorrect' ? justificativa : null,
    sugestao_novo_ds: sugestaoNovoDS || null
  });

  if (success) {
    handleClose();
    onSuccess?.();
  }
};`,
    esfor√ßo: 'baixo',
    prioridade: 3
  },
  {
    id: 'FE-005',
    severidade: 'm√©dia',
    categoria: 'performance',
    componente: 'useAnnotationJobs',
    arquivo: 'src/hooks/useAnnotationJobs.ts',
    descri√ß√£o: 'Sem pagina√ß√£o para jobs longos',
    impacto: 'Performance degrada com muitos jobs. Uso excessivo de mem√≥ria. UI lenta.',
    solu√ß√£o: `// Implementar pagina√ß√£o:
export function useAnnotationJobs(limit: number = 20, offset: number = 0) {
  const [jobs, setJobs] = useState<AnnotationJob[]>([]);
  const [totalCount, setTotalCount] = useState(0);
  const [isLoading, setIsLoading] = useState(true);

  const fetchJobs = async () => {
    try {
      setIsLoading(true);

      // Buscar total de jobs
      const { count } = await supabase
        .from('annotation_jobs')
        .select('*', { count: 'exact', head: true });

      setTotalCount(count || 0);

      // Buscar jobs paginados
      const { data, error } = await supabase
        .from('annotation_jobs')
        .select('*')
        .order('tempo_inicio', { ascending: false })
        .range(offset, offset + limit - 1);

      if (error) throw error;
      setJobs(data || []);
    } catch (err) {
      console.error('Erro ao carregar jobs:', err);
    } finally {
      setIsLoading(false);
    }
  };

  return {
    jobs,
    totalCount,
    isLoading,
    hasMore: offset + limit < totalCount,
    refetch: fetchJobs
  };
}`,
    esfor√ßo: 'm√©dio',
    prioridade: 4
  }
];

// ============= FASE 3: ARQUITETURA E DESIGN =============

export const architectureBugs: BugReport[] = [
  {
    id: 'ARCH-001',
    severidade: 'alta',
    categoria: 'performance',
    componente: 'global',
    arquivo: 'm√∫ltiplos',
    descri√ß√£o: 'Falta cache estrat√©gico para dados est√°ticos',
    impacto: 'Requisi√ß√µes desnecess√°rias. Performance ruim. Custo computacional alto.',
    solu√ß√£o: `// Implementar cache para tagsets e dados est√°ticos:
// src/hooks/useTagsets.ts
import { useQuery } from '@tanstack/react-query';

export function useTagsets() {
  return useQuery({
    queryKey: ['tagsets'],
    queryFn: async () => {
      const { data, error } = await supabase
        .from('semantic_tagset')
        .select('*')
        .eq('status', 'ativo');
      
      if (error) throw error;
      return data;
    },
    staleTime: 5 * 60 * 1000, // 5 minutos
    cacheTime: 30 * 60 * 1000, // 30 minutos
  });
}`,
    esfor√ßo: 'baixo',
    prioridade: 2
  },
  {
    id: 'ARCH-002',
    severidade: 'm√©dia',
    categoria: 'funcional',
    componente: 'global',
    arquivo: 'm√∫ltiplos',
    descri√ß√£o: 'Falta sistema de retry para falhas transit√≥rias',
    impacto: 'Falhas desnecess√°rias em condi√ß√µes de rede inst√°vel. UX ruim.',
    solu√ß√£o: `// Implementar retry com exponential backoff:
// src/lib/retryUtils.ts
export async function retryWithBackoff<T>(
  fn: () => Promise<T>,
  maxRetries: number = 3,
  baseDelay: number = 1000
): Promise<T> {
  let lastError: Error;
  
  for (let attempt = 0; attempt <= maxRetries; attempt++) {
    try {
      return await fn();
    } catch (error) {
      lastError = error as Error;
      
      if (attempt === maxRetries) break;
      
      const delay = baseDelay * Math.pow(2, attempt);
      await new Promise(resolve => setTimeout(resolve, delay));
    }
  }
  
  throw lastError!;
}

// Uso:
const data = await retryWithBackoff(async () => {
  const { data, error } = await supabase
    .from('annotation_jobs')
    .select('*');
  
  if (error) throw error;
  return data;
});`,
    esfor√ßo: 'm√©dio',
    prioridade: 3
  },
  {
    id: 'ARCH-003',
    severidade: 'baixa',
    categoria: 'ux',
    componente: 'global',
    arquivo: 'm√∫ltiplos',
    descri√ß√£o: 'Falta sistema de notifica√ß√µes centralizadas',
    impacto: 'Inconsist√™ncia nas mensagens de erro. UX ruim.',
    solu√ß√£o: `// Criar sistema de notifica√ß√µes centralizadas:
// src/lib/notifications.ts
import { toast } from 'sonner';

export const notifications = {
  success: (message: string, description?: string) => {
    toast.success(message, { description });
  },
  
  error: (message: string, error?: Error | string) => {
    const description = error instanceof Error ? error.message : error;
    toast.error(message, { description });
    console.error(message, error);
  },
  
  info: (message: string, description?: string) => {
    toast.info(message, { description });
  },
  
  warning: (message: string, description?: string) => {
    toast.warning(message, { description });
  }
};`,
    esfor√ßo: 'baixo',
    prioridade: 4
  }
];

// ============= ESTRAT√âGIA DE REFATORA√á√ÉO =============

export const refactoringStrategy: RefactoringStrategy[] = [
  {
    fase: 1,
    titulo: 'Corre√ß√µes Cr√≠ticas de Seguran√ßa e Funcionalidade',
    objetivos: [
      'Implementar autentica√ß√£o real em edge functions',
      'Adicionar valida√ß√£o de entrada com Zod',
      'Implementar rate limiting',
      'Corrigir retorno de jobId em dictionary processors'
    ],
    componentes: [
      'supabase/functions/annotate-semantic/index.ts',
      'supabase/functions/process-dialectal-dictionary/index.ts',
      'todas as edge functions'
    ],
    esfor√ßo_total: '4-6 horas',
    economia_cr√©ditos: 'Alta (previne bugs em produ√ß√£o)',
    prazo_sugerido: '1-2 dias'
  },
  {
    fase: 2,
    titulo: 'Otimiza√ß√£o de Performance Backend',
    objetivos: [
      'Implementar batching eficiente em dictionary processors',
      'Adicionar timeout e controle de recursos',
      'Implementar sistema de retry',
      'Otimizar queries do banco'
    ],
    componentes: [
      'supabase/functions/process-*-dictionary/index.ts',
      'supabase/functions/annotate-semantic/index.ts'
    ],
    esfor√ßo_total: '6-8 horas',
    economia_cr√©ditos: 'Muito Alta (reduz timeouts e falhas)',
    prazo_sugerido: '2-3 dias'
  },
  {
    fase: 3,
    titulo: 'Corre√ß√µes Frontend e UX',
    objetivos: [
      'Corrigir memory leaks em hooks',
      'Implementar detec√ß√£o de jobs travados',
      'Adicionar valida√ß√µes nos formul√°rios',
      'Implementar pagina√ß√£o'
    ],
    componentes: [
      'src/hooks/useAnnotationJobs.ts',
      'src/hooks/useDictionaryImportJobs.ts',
      'src/components/advanced/ValidationInterface.tsx',
      'src/components/advanced/DictionaryImportInterface.tsx'
    ],
    esfor√ßo_total: '4-5 horas',
    economia_cr√©ditos: 'M√©dia (melhora UX e previne erros)',
    prazo_sugerido: '1-2 dias'
  },
  {
    fase: 4,
    titulo: 'Melhorias Arquiteturais',
    objetivos: [
      'Implementar cache estrat√©gico',
      'Criar sistema de notifica√ß√µes centralizadas',
      'Adicionar monitoramento e logs',
      'Documentar padr√µes de c√≥digo'
    ],
    componentes: [
      'src/lib/retryUtils.ts (novo)',
      'src/lib/notifications.ts (novo)',
      'src/hooks/useTagsets.ts',
      'm√∫ltiplos componentes'
    ],
    esfor√ßo_total: '3-4 horas',
    economia_cr√©ditos: 'Baixa (preven√ß√£o futura)',
    prazo_sugerido: '1-2 dias'
  }
];

// ============= RESUMO EXECUTIVO =============

export const executiveSummary = {
  dataAuditoria: '2024-11-16',
  totalBugs: backendBugs.length + frontendBugs.length + architectureBugs.length,
  bugsBackend: backendBugs.length,
  bugsFrontend: frontendBugs.length,
  bugsArquitetura: architectureBugs.length,
  
  distribuicaoPorSeveridade: {
    cr√≠tica: [...backendBugs, ...frontendBugs, ...architectureBugs].filter(b => b.severidade === 'cr√≠tica').length,
    alta: [...backendBugs, ...frontendBugs, ...architectureBugs].filter(b => b.severidade === 'alta').length,
    m√©dia: [...backendBugs, ...frontendBugs, ...architectureBugs].filter(b => b.severidade === 'm√©dia').length,
    baixa: [...backendBugs, ...frontendBugs, ...architectureBugs].filter(b => b.severidade === 'baixa').length,
  },
  
  distribuicaoPorCategoria: {
    seguran√ßa: [...backendBugs, ...frontendBugs, ...architectureBugs].filter(b => b.categoria === 'seguran√ßa').length,
    performance: [...backendBugs, ...frontendBugs, ...architectureBugs].filter(b => b.categoria === 'performance').length,
    funcional: [...backendBugs, ...frontendBugs, ...architectureBugs].filter(b => b.categoria === 'funcional').length,
    ux: [...backendBugs, ...frontendBugs, ...architectureBugs].filter(b => b.categoria === 'ux').length,
  },
  
  esforcoTotal: '17-23 horas',
  prazoTotal: '5-9 dias (com 2-3h/dia)',
  
  economiaEstimada: {
    creditosPrevenidos: '200-300 cr√©ditos (corre√ß√µes evitadas)',
    tempoPoupado: '15-20 horas (debugging futuro)',
    riscosEliminados: '8 bugs cr√≠ticos/altos'
  },
  
  recomendacoesPrioritarias: [
    '1. Implementar autentica√ß√£o real (BE-001) - CR√çTICO',
    '2. Corrigir retorno de jobId (BE-002) - CR√çTICO',
    '3. Adicionar valida√ß√£o de entrada (BE-004) - ALTA',
    '4. Corrigir memory leaks (FE-001) - ALTA',
    '5. Implementar batching eficiente (BE-003) - ALTA'
  ],
  
  metasDeQualidade: {
    taxaBugsPreProducao: '< 5%',
    coberturaTestes: '> 60%',
    tempoMedioCorre√ß√£o: '< 2 horas',
    satisfacaoUsuario: '> 4.5/5'
  }
};

// ============= PLANO DE A√á√ÉO IMEDIATO =============

export const actionPlan = {
  semana1: {
    titulo: 'Corre√ß√µes Cr√≠ticas',
    tarefas: [
      'Implementar autentica√ß√£o real em annotate-semantic',
      'Corrigir retorno de jobId em process-dialectal-dictionary',
      'Adicionar valida√ß√£o b√°sica em todas edge functions',
      'Implementar rate limiting b√°sico'
    ],
    respons√°vel: 'Dev Backend',
    prazo: '2 dias',
    prioridade: 'CR√çTICA'
  },
  
  semana2: {
    titulo: 'Otimiza√ß√µes Backend',
    tarefas: [
      'Implementar batching eficiente em dictionary processors',
      'Adicionar timeout em processamento background',
      'Implementar sistema de retry b√°sico',
      'Otimizar queries mais lentas'
    ],
    respons√°vel: 'Dev Backend',
    prazo: '3 dias',
    prioridade: 'ALTA'
  },
  
  semana3: {
    titulo: 'Corre√ß√µes Frontend',
    tarefas: [
      'Corrigir memory leaks em hooks Realtime',
      'Implementar detec√ß√£o de jobs travados',
      'Adicionar valida√ß√µes nos formul√°rios',
      'Melhorar feedback de erros'
    ],
    respons√°vel: 'Dev Frontend',
    prazo: '2 dias',
    prioridade: 'ALTA'
  },
  
  semana4: {
    titulo: 'Melhorias Arquiteturais',
    tarefas: [
      'Implementar cache estrat√©gico',
      'Criar sistema de notifica√ß√µes centralizadas',
      'Adicionar pagina√ß√£o em listas grandes',
      'Documentar padr√µes estabelecidos'
    ],
    respons√°vel: 'Dev Full Stack',
    prazo: '2 dias',
    prioridade: 'M√âDIA'
  }
};

// ============= CHECKLIST DE VALIDA√á√ÉO =============

export const validationChecklist = {
  backend: [
    '[ ] Todas edge functions t√™m autentica√ß√£o real',
    '[ ] Todas edge functions t√™m valida√ß√£o de entrada com Zod',
    '[ ] Todas edge functions t√™m rate limiting',
    '[ ] Todas edge functions retornam jobId quando aplic√°vel',
    '[ ] Processamento em background tem timeout',
    '[ ] Batching implementado em importa√ß√µes',
    '[ ] Sistema de retry implementado',
    '[ ] Logs adequados em todas edge functions'
  ],
  
  frontend: [
    '[ ] Todos hooks Realtime fazem cleanup correto',
    '[ ] Polling tem detec√ß√£o de jobs travados',
    '[ ] Formul√°rios t√™m valida√ß√£o completa',
    '[ ] Feedback de erro √© claro e acion√°vel',
    '[ ] Listas grandes t√™m pagina√ß√£o',
    '[ ] Cache implementado para dados est√°ticos',
    '[ ] Loading states implementados',
    '[ ] Tratamento de erro consistente'
  ],
  
  qualidade: [
    '[ ] Taxa de bugs < 5%',
    '[ ] Tempo de corre√ß√£o < 2h',
    '[ ] Performance n√£o regrediu',
    '[ ] UX melhorou visivelmente',
    '[ ] Documenta√ß√£o atualizada',
    '[ ] Code review realizado',
    '[ ] Testes manuais realizados',
    '[ ] Deploy em staging testado'
  ]
};

export default {
  backendBugs,
  frontendBugs,
  architectureBugs,
  refactoringStrategy,
  executiveSummary,
  actionPlan,
  validationChecklist
};
