// ğŸ”¥ DEPLOY TIMESTAMP: 2025-01-20T18:30:00Z - v5.1: Rate Limiting Fixed (5 parallel + 1s delay)
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2.81.1';
import { withRetry } from '../_shared/retry.ts';

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

const CHUNK_SIZE = 5000;
const MAX_RETRIES = 3;
const DICTIONARY_URLS = [
  'https://raw.githubusercontent.com/ProfessorGeovaniHenrique/estilisticadecorpus/main/public/Dicionarios/GutenbergNOVO.txt',
];

interface VerbeteGutenberg {
  verbete: string;
  verbete_normalizado: string;
  classe_gramatical?: string;
  definicoes?: Array<{ tipo?: string; texto: string }>;
  etimologia?: string;
  exemplos?: string[];
  sinonimos?: string[];
  antonimos?: string[];
  areas_conhecimento?: string[];
  origem_lingua?: string;
  regional?: boolean;
  popular?: boolean;
  figurado?: boolean;
  arcaico?: boolean;
  genero?: string;
  derivados?: string[];
  expressoes?: string[];
  confianca_extracao: number;
}

interface RequestBody {
  resumeJobId?: string;
  startIndex?: number;
}

function normalizeText(text: string): string {
  return text
    .toLowerCase()
    .normalize('NFD')
    .replace(/[\u0300-\u036f]/g, '')
    .trim();
}

// ============= PARSING INTELIGENTE COM GEMINI FLASH =============

async function parseWithGemini(entryText: string): Promise<VerbeteGutenberg | null> {
  try {
    const LOVABLE_API_KEY = Deno.env.get('LOVABLE_API_KEY');
    if (!LOVABLE_API_KEY) {
      console.error('âŒ LOVABLE_API_KEY nÃ£o configurada');
      return null;
    }

    const response = await fetch('https://ai.gateway.lovable.dev/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${LOVABLE_API_KEY}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'google/gemini-2.5-flash',
        temperature: 0,
        messages: [
          {
            role: 'system',
            content: 'VocÃª Ã© um linguista especializado em dicionÃ¡rios antigos. Sua tarefa Ã© extrair informaÃ§Ãµes estruturadas de verbetes brutos do DicionÃ¡rio Gutenberg. O formato Ã© instÃ¡vel, entÃ£o use seu julgamento para identificar o verbete principal, a classe gramatical (se houver) e todas as linhas que compÃµem a definiÃ§Ã£o.'
          },
          {
            role: 'user',
            content: `Analise o seguinte verbete cru e retorne APENAS um objeto JSON no formato abaixo. Se nÃ£o for um verbete vÃ¡lido, retorne null.

Formato JSON desejado:
{
  "verbete": "string (sem asteriscos ou vÃ­rgulas)",
  "classe_gramatical": "string ou null",
  "definicoes": ["string", "string", ...]
}

Verbete Cru:
"""
${entryText}
"""

Retorne APENAS o JSON, sem texto adicional.`
          }
        ]
      })
    });

    if (!response.ok) {
      if (response.status === 429) {
        console.warn('âš ï¸ Rate limit atingido (429)');
        throw new Error('RATE_LIMIT');
      }
      console.error(`âŒ Gemini API error: ${response.status}`);
      return null;
    }

    const data = await response.json();
    const content = data.choices?.[0]?.message?.content;
    
    if (!content) return null;

    // Extrair JSON do conteÃºdo
    const jsonMatch = content.match(/\{[\s\S]*\}/);
    if (!jsonMatch) {
      console.warn('âš ï¸ Resposta sem JSON vÃ¡lido');
      return null;
    }

    const parsed = JSON.parse(jsonMatch[0]);
    
    if (!parsed.verbete || typeof parsed.verbete !== 'string') {
      return null;
    }

    const verbeteData: VerbeteGutenberg = {
      verbete: parsed.verbete.trim(),
      verbete_normalizado: normalizeText(parsed.verbete),
      classe_gramatical: parsed.classe_gramatical || undefined,
      definicoes: parsed.definicoes?.map((d: string) => ({ texto: d })) || undefined,
      confianca_extracao: 0.98,
    };

    return verbeteData;
    
  } catch (error: any) {
    if (error.message === 'RATE_LIMIT') {
      throw error;
    }
    console.error('âŒ Erro ao parsear com Gemini:', error.message);
    return null;
  }
}

async function parseWithGeminiRetry(entryText: string, maxRetries = 3): Promise<VerbeteGutenberg | null> {
  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      return await parseWithGemini(entryText);
    } catch (error: any) {
      if (error.message === 'RATE_LIMIT') {
        const delay = attempt * 5000; // 5s, 10s, 15s
        if (attempt < maxRetries) {
          console.warn(`âš ï¸ Rate limit - aguardando ${delay/1000}s (tentativa ${attempt}/${maxRetries})`);
          await new Promise(resolve => setTimeout(resolve, delay));
          continue;
        }
      }
      throw error;
    }
  }
  return null;
}

async function processBatchWithConcurrency<T, R>(
  items: T[],
  processFn: (item: T) => Promise<R>,
  concurrencyLimit: number = 5
): Promise<R[]> {
  const results: R[] = [];
  
  for (let i = 0; i < items.length; i += concurrencyLimit) {
    const batch = items.slice(i, i + concurrencyLimit);
    const batchResults = await Promise.all(
      batch.map(item => processFn(item))
    );
    results.push(...batchResults);
    
    console.log(`   âœ… Processados ${Math.min(i + concurrencyLimit, items.length)}/${items.length} verbetes com IA`);
    
    // Pausa de 1s entre batches para evitar rate limiting
    if (i + concurrencyLimit < items.length) {
      await new Promise(resolve => setTimeout(resolve, 1000));
    }
  }
  
  return results;
}

async function checkCancellation(jobId: string, supabaseClient: any): Promise<void> {
  const { data: job, error } = await supabaseClient
    .from('dictionary_import_jobs')
    .select('is_cancelling, status')
    .eq('id', jobId)
    .single();

  if (error || !job) {
    throw new Error('Erro ao verificar status do job');
  }

  if (job.is_cancelling || job.status === 'cancelado') {
    await supabaseClient
      .from('dictionary_import_jobs')
      .update({
        status: 'cancelado',
        cancelled_at: new Date().toISOString(),
        tempo_fim: new Date().toISOString(),
        erro_mensagem: 'Job cancelado pelo usuÃ¡rio'
      })
      .eq('id', jobId);

    throw new Error('JOB_CANCELLED');
  }
}

async function processChunk(
  jobId: string,
  verbetes: string[],
  startIndex: number,
  supabaseClient: any
): Promise<void> {
  try {
    console.log(`ğŸ“¦ Processando chunk: ${startIndex} a ${Math.min(startIndex + CHUNK_SIZE, verbetes.length)}`);
    
    await checkCancellation(jobId, supabaseClient);

    const endIndex = Math.min(startIndex + CHUNK_SIZE, verbetes.length);
    const chunk = verbetes.slice(startIndex, endIndex);

    let definicoesVazias = 0;

    console.log(`ğŸ¤– Processando ${chunk.length} verbetes com IA (Gemini Flash v5.1)`);
    console.log(`   ConcorrÃªncia: 5 chamadas paralelas + 1s delay entre batches`);
    console.log(`   Tempo estimado: ~${Math.ceil(chunk.length / 5 * 2)}s`);

    const parsedBatch = await processBatchWithConcurrency(
      chunk,
      async (v) => {
        const parsed = await parseWithGeminiRetry(v);
        if (parsed && (!parsed.definicoes || parsed.definicoes.length === 0)) {
          definicoesVazias++;
        }
        return parsed;
      },
      5 // ConcorrÃªncia controlada para evitar rate limits
    );

    const validParsed = parsedBatch.filter((v): v is VerbeteGutenberg => v !== null);

    console.log(`âœ… IA processou ${parsedBatch.length} verbetes`);
    console.log(`   VÃ¡lidos: ${validParsed.length}`);
    console.log(`   Rejeitados: ${parsedBatch.length - validParsed.length}`);
    console.log(`   DefiniÃ§Ãµes vazias: ${definicoesVazias}`);

    if (validParsed.length > 0) {
      await withRetry(
        async () => {
          const { error } = await supabaseClient
            .from('gutenberg_lexicon')
            .insert(validParsed);
          if (error) throw error;
        },
        MAX_RETRIES,
        1000
      );
    }

    // Atualizar progresso
    const progressPercentage = Math.round((endIndex / verbetes.length) * 100);
    await supabaseClient
      .from('dictionary_import_jobs')
      .update({
        verbetes_processados: endIndex,
        verbetes_inseridos: startIndex + validParsed.length,
        progresso: progressPercentage,
        atualizado_em: new Date().toISOString(),
      })
      .eq('id', jobId);

    console.log(`ğŸ“Š Progresso: ${endIndex}/${verbetes.length} (${progressPercentage}%) - ${validParsed.length} inseridos`);

    // Se ainda hÃ¡ verbetes, invocar prÃ³ximo chunk
    if (endIndex < verbetes.length) {
      console.log(`ğŸ”„ Auto-invocando prÃ³ximo chunk...`);
      
      const { error: invokeError } = await supabaseClient.functions.invoke('import-gutenberg-backend', {
        body: {
          resumeJobId: jobId,
          startIndex: endIndex,
        }
      });

      if (invokeError) {
        console.error('âŒ Erro ao invocar prÃ³ximo chunk:', invokeError);
        throw invokeError;
      }
    } else {
      // Concluir e limpar
      console.log('âœ… Todos os chunks processados! Finalizando...');
      
      await supabaseClient
        .from('dictionary_import_jobs')
        .update({
          status: 'concluido',
          tempo_fim: new Date().toISOString(),
          progresso: 100,
          atualizado_em: new Date().toISOString(),
        })
        .eq('id', jobId);

      // Limpar arquivo temporÃ¡rio do Storage
      const { error: deleteError } = await supabaseClient.storage
        .from('corpus')
        .remove([`temp-imports/gutenberg-${jobId}.json`]);

      if (deleteError) {
        console.warn('âš ï¸ Erro ao deletar arquivo temporÃ¡rio:', deleteError);
      } else {
        console.log('ğŸ—‘ï¸ Arquivo temporÃ¡rio removido do Storage');
      }

      console.log(`âœ… IMPORTAÃ‡ÃƒO COMPLETA! Total de verbetes processados: ${verbetes.length}`);
    }
  } catch (error: any) {
    if (error.message === 'JOB_CANCELLED') {
      console.log('ğŸ›‘ Job cancelado pelo usuÃ¡rio');
      return;
    }

    console.error('âŒ Erro ao processar chunk:', error);
    
    await supabaseClient
      .from('dictionary_import_jobs')
      .update({
        status: 'erro',
        erro_mensagem: `Erro no chunk ${startIndex}: ${error.message}`,
        tempo_fim: new Date().toISOString(),
        atualizado_em: new Date().toISOString(),
      })
      .eq('id', jobId);

    throw error;
  }
}

Deno.serve(async (req) => {
  const requestId = crypto.randomUUID();
  const startTime = Date.now();
  
  console.log(`\n${'='.repeat(70)}`);
  console.log(`ğŸ”µ REQUEST RECEBIDA [${requestId}]`);
  console.log(`   Method: ${req.method}`);
  console.log(`   URL: ${req.url}`);
  console.log(`   Timestamp: ${new Date().toISOString()}`);
  console.log(`${'='.repeat(70)}\n`);
  
  if (req.method === 'OPTIONS') {
    console.log('âœ… Respondendo CORS preflight');
    return new Response(null, { headers: corsHeaders });
  }

  try {
    console.log('ğŸš€ VERSÃƒO 5.1 - Rate Limiting Fixed (5 parallel + 1s delay)');
    console.log(`ğŸ“Š Request ID: ${requestId}`);
    
    const supabase = createClient(
      Deno.env.get('SUPABASE_URL')!,
      Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!
    );

    let body: RequestBody = {};
    try {
      body = await req.json();
      console.log('ğŸ“¦ Body recebido:', JSON.stringify(body, null, 2));
    } catch (parseError) {
      console.log('â„¹ï¸ Nenhum body enviado (ou JSON invÃ¡lido), usando body vazio');
    }

    // ===== FLUXO DE CONTINUAÃ‡ÃƒO (Chunk subsequente) =====
    if (body.resumeJobId) {
      const { resumeJobId, startIndex } = body;
      
      if (typeof startIndex !== 'number') {
        throw new Error('startIndex deve ser um nÃºmero');
      }
      
      console.log(`ğŸ”„ Continuando job: ${resumeJobId}, startIndex: ${startIndex}`);

      // Baixar verbetes do Storage
      const { data: downloadData, error: downloadError } = await supabase.storage
        .from('corpus')
        .download(`temp-imports/gutenberg-${resumeJobId}.json`);

      if (downloadError || !downloadData) {
        throw new Error(`Erro ao baixar arquivo temporÃ¡rio: ${downloadError?.message}`);
      }

      const fileContent = await downloadData.text();
      const verbetes = JSON.parse(fileContent);

      console.log(`ğŸ“š Verbetes carregados do Storage: ${verbetes.length}`);

      // Processar chunk em background
      processChunk(resumeJobId, verbetes, startIndex, supabase).catch(console.error);

      return new Response(
        JSON.stringify({ 
          success: true, 
          message: `Processando chunk ${startIndex}`,
          chunk: startIndex 
        }),
        { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      );
    }

    // ===== FLUXO INICIAL (Primeira invocaÃ§Ã£o) =====
    console.log('ğŸ“¥ Iniciando nova importaÃ§Ã£o...');

    // Tentar baixar de mÃºltiplas URLs
    let fileContent = '';
    let usedUrl = '';

    for (const url of DICTIONARY_URLS) {
      console.log(`ğŸŒ Tentando baixar de: ${url}`);
      try {
        const response = await fetch(url);
        if (response.ok) {
          fileContent = await response.text();
          usedUrl = url;
          console.log(`âœ… Arquivo baixado com sucesso de: ${url}`);
          console.log(`ğŸ“„ Tamanho: ${fileContent.length} caracteres`);
          break;
        }
      } catch (fetchError) {
        console.warn(`âš ï¸ Erro ao baixar de ${url}:`, fetchError);
      }
    }

    if (!fileContent) {
      throw new Error('Nenhuma URL de dicionÃ¡rio disponÃ­vel ou acessÃ­vel');
    }

    // ğŸ” DEBUG DETALHADO - CONTEÃšDO BRUTO DO ARQUIVO
    console.log("\nğŸ” DEBUG - InÃ­cio do arquivo (primeiros 1000 chars):");
    console.log("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    console.log(fileContent.substring(0, 1000));
    console.log("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");

    // Log das primeiras linhas para debug
    const firstLines = fileContent.split('\n').slice(0, 10);
    console.log('ğŸ“ Primeiras 10 linhas do arquivo:');
    firstLines.forEach((line, idx) => console.log(`   ${idx + 1}: ${line.substring(0, 80)}`));

    // Parse verbetes com estratÃ©gia CORRIGIDA
    console.log('ğŸ” Aplicando estratÃ©gia de parsing corrigida...');
    
    // Remover cabeÃ§alhos do Project Gutenberg se existirem
    const startMarker = fileContent.indexOf('*** START');
    const endMarker = fileContent.indexOf('*** END');
    
    let contentToParse = fileContent;
    if (startMarker !== -1) {
      const startPos = fileContent.indexOf('\n', startMarker) + 1;
      contentToParse = endMarker !== -1 
        ? fileContent.substring(startPos, endMarker)
        : fileContent.substring(startPos);
      console.log('âœ‚ï¸ Removido cabeÃ§alho/rodapÃ© do Project Gutenberg');
    }

    // Split por verbetes - REGEX CORRIGIDO: Quebra em \n seguido de *palavra*,
    console.log('ğŸ” Aplicando split CORRIGIDO: /\\n(?=\\*[A-ZÃ-Ãš][^*]*\\*,)/');
    const verbetes = contentToParse
      .split(/\n(?=\*[A-ZÃ-Ãš][^*]*\*,)/)
      .map(v => v.trim())
      .filter(v => {
        // Validar: Deve comeÃ§ar com *palavra*, e ter conteÃºdo
        const match = v.match(/^\*[A-ZÃÃ€ÃƒÃ‚Ã‰ÃŠÃÃ“Ã”Ã•ÃšÃ‡Ã‘a-zÃ¡Ã Ã£Ã¢Ã©ÃªÃ­Ã³Ã´ÃµÃºÃ§Ã±\s-]+\*,/);
        const isValid = match !== null && v.length > 10;
        
        if (!isValid && v.length > 0) {
          console.log(`âŒ [REJEITADO] "${v.substring(0, 50)}..."`);
        }
        
        return isValid;
      });

    // ğŸ” DEBUG COMPLETO - RESULTADO DO SPLIT
    console.log(`\nğŸ” DEBUG - Total de verbetes apÃ³s split: ${verbetes.length}`);
    console.log("\nğŸ” DEBUG - Primeiros 5 verbetes COMPLETOS para inspeÃ§Ã£o:\n");
    verbetes.slice(0, 5).forEach((v, i) => {
      console.log(`â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—`);
      console.log(`â•‘ VERBETE ${i + 1} (primeiros 300 chars)                          â•‘`);
      console.log(`â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£`);
      console.log(v.substring(0, 300));
      console.log(`â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n`);
    });

    console.log(`\nğŸ“š Total de verbetes identificados: ${verbetes.length}`);
    console.log(`ğŸ“Š EstatÃ­sticas de Split:`);
    console.log(`   - Linhas totais: ${fileContent.split('\n').length}`);
    console.log(`   - Verbetes vÃ¡lidos (padrÃ£o *palavra*,): ${verbetes.length}`);
    console.log(`   - MÃ©dia de caracteres por verbete: ${Math.round(contentToParse.length / verbetes.length)}`);
    console.log(`   - Blocos rejeitados no filter: ${contentToParse.split(/(?=\n\*[A-ZÃÃ€ÃƒÃ‚Ã‰ÃŠÃÃ“Ã”Ã•ÃšÃ‡Ã‘a-zÃ¡Ã Ã£Ã¢Ã©ÃªÃ­Ã³Ã´ÃµÃºÃ§Ã±\s-]+\*,)/).length - verbetes.length}`);

    if (verbetes.length === 0) {
      console.error('âŒ Nenhum verbete vÃ¡lido encontrado!');
      console.log('ğŸ“„ Amostra do conteÃºdo (primeiros 500 chars):');
      console.log(contentToParse.substring(0, 500));
      throw new Error('Nenhum verbete vÃ¡lido encontrado no arquivo. Verifique o formato.');
    }

    // Criar job
    const { data: job, error: jobError } = await supabase
      .from('dictionary_import_jobs')
      .insert({
        tipo_dicionario: 'gutenberg',
        status: 'processando',
        total_verbetes: verbetes.length,
        verbetes_processados: 0,
        verbetes_inseridos: 0,
        progresso: 0,
        metadata: { 
          source_url: usedUrl,
          chunk_size: CHUNK_SIZE,
          total_chunks: Math.ceil(verbetes.length / CHUNK_SIZE)
        },
        tempo_inicio: new Date().toISOString(),
      })
      .select()
      .single();

    if (jobError || !job) {
      console.error('âŒ Erro ao criar job:', jobError);
      throw new Error(`Erro ao criar job: ${jobError?.message}`);
    }

    console.log(`âœ… Job criado: ${job.id}`);

    // Salvar verbetes no Storage para uso nos prÃ³ximos chunks
    const { error: uploadError } = await supabase.storage
      .from('corpus')
      .upload(
        `temp-imports/gutenberg-${job.id}.json`,
        JSON.stringify(verbetes),
        {
          contentType: 'application/json',
          upsert: true,
        }
      );

    if (uploadError) {
      console.error('âŒ Erro ao salvar no Storage:', uploadError);
      throw new Error(`Erro ao salvar arquivo temporÃ¡rio: ${uploadError.message}`);
    }

    console.log(`ğŸ’¾ Verbetes salvos no Storage: temp-imports/gutenberg-${job.id}.json`);

    // Processar primeiro chunk em background
    console.log('ğŸš€ Iniciando processamento do primeiro chunk em background...');
    processChunk(job.id, verbetes, 0, supabase).catch(console.error);

    const responseTime = Date.now() - startTime;
    console.log(`\n${'='.repeat(70)}`);
    console.log(`âœ… RESPOSTA ENVIADA [${requestId}]`);
    console.log(`   Status: 200 OK`);
    console.log(`   Tempo de resposta: ${responseTime}ms`);
    console.log(`   Job ID: ${job.id}`);
    console.log(`   Total verbetes: ${verbetes.length}`);
    console.log(`${'='.repeat(70)}\n`);

    return new Response(
      JSON.stringify({
        success: true,
        jobId: job.id,
        totalVerbetes: verbetes.length,
        totalChunks: Math.ceil(verbetes.length / CHUNK_SIZE),
        message: `ImportaÃ§Ã£o iniciada com ${verbetes.length} verbetes`,
        requestId,
        responseTime: `${responseTime}ms`,
      }),
      { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
    );

  } catch (error: any) {
    const responseTime = Date.now() - startTime;
    console.error(`\n${'='.repeat(70)}`);
    console.error(`âŒ ERRO FATAL [${requestId}]`);
    console.error(`   Tempo atÃ© erro: ${responseTime}ms`);
    console.error(`   Erro: ${error.message}`);
    console.error(`   Stack: ${error.stack}`);
    console.error(`${'='.repeat(70)}\n`);
    
    return new Response(
      JSON.stringify({ 
        success: false, 
        error: error.message,
        stack: error.stack,
        requestId,
        responseTime: `${responseTime}ms`,
      }),
      { 
        status: 500, 
        headers: { ...corsHeaders, 'Content-Type': 'application/json' } 
      }
    );
  }
});
