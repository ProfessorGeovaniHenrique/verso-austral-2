import { createClient } from 'https://esm.sh/@supabase/supabase-js@2';

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

interface ValidationRequest {
  dictionaryType: 'dialectal' | 'gutenberg' | 'rochaPombo' | 'unesp';
  batchSize: 100 | 1000 | 10000;
}

Deno.serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders });
  }

  try {
    const supabase = createClient(
      Deno.env.get('SUPABASE_URL') ?? '',
      Deno.env.get('SUPABASE_SERVICE_ROLE_KEY') ?? ''
    );

    const { dictionaryType, batchSize }: ValidationRequest = await req.json();

    console.log(`üîç Iniciando valida√ß√£o em lote: ${dictionaryType}, tamanho: ${batchSize}`);

    let tableName: string;
    let validationCriteria: any = {};

    // Determinar tabela e crit√©rios
    switch (dictionaryType) {
      case 'dialectal':
        tableName = 'dialectal_lexicon';
        validationCriteria = {
          validado_humanamente: false,
          confianca_extracao: { gte: 0.90 }
        };
        break;
      
      case 'gutenberg':
        tableName = 'gutenberg_lexicon';
        validationCriteria = {
          validado: false,
          confianca_extracao: { gte: 0.90 }
        };
        break;
      
      case 'rochaPombo':
        tableName = 'lexical_synonyms';
        validationCriteria = {
          validado_humanamente: false,
          confianca_extracao: { gte: 0.90 },
          fonte: 'rocha_pombo'
        };
        break;
      
      case 'unesp':
        // UNESP n√£o tem campo de valida√ß√£o (j√° √© confi√°vel)
        return new Response(
          JSON.stringify({ 
            validated: 0, 
            skipped: 0, 
            message: 'UNESP j√° possui dados validados academicamente' 
          }),
          { headers: { ...corsHeaders, 'Content-Type': 'application/json' }, status: 200 }
        );
      
      default:
        throw new Error(`Tipo de dicion√°rio inv√°lido: ${dictionaryType}`);
    }

    // Buscar entradas n√£o validadas com alta confian√ßa
    let query = supabase
      .from(tableName)
      .select('id')
      .gte('confianca_extracao', 0.90)
      .limit(batchSize);

    if (dictionaryType === 'rochaPombo') {
      query = query.eq('fonte', 'rocha_pombo').eq('validado_humanamente', false);
    } else if (dictionaryType === 'dialectal') {
      query = query.eq('validado_humanamente', false);
    } else {
      query = query.eq('validado', false);
    }

    const { data: entries, error: fetchError } = await query;

    if (fetchError) {
      throw new Error(`Erro ao buscar entradas: ${fetchError.message}`);
    }

    if (!entries || entries.length === 0) {
      console.log('‚ö†Ô∏è Nenhuma entrada encontrada para valida√ß√£o');
      return new Response(
        JSON.stringify({ validated: 0, skipped: 0, message: 'Nenhuma entrada dispon√≠vel para valida√ß√£o' }),
        { headers: { ...corsHeaders, 'Content-Type': 'application/json' }, status: 200 }
      );
    }

    // Helper para chunking
    const chunkArray = <T>(array: T[], size: number): T[][] => {
      const chunks: T[][] = [];
      for (let i = 0; i < array.length; i += size) {
        chunks.push(array.slice(i, i + size));
      }
      return chunks;
    };

    // Atualizar entradas em chunks de 100 (evita URL limit do PostgREST)
    const ids = entries.map(e => e.id);
    const updateField = (dictionaryType === 'dialectal' || dictionaryType === 'rochaPombo') 
      ? 'validado_humanamente' 
      : 'validado';
    const chunks = chunkArray(ids, 100);
    let totalUpdated = 0;

    console.log(`üîÑ Atualizando ${ids.length} entradas na tabela ${tableName}`);
    console.log(`üìù Campo de update: ${updateField} = true`);
    console.log(`üì¶ Processando ${chunks.length} chunks de ~100 IDs cada`);

    // Processar cada chunk sequencialmente
    for (let i = 0; i < chunks.length; i++) {
      const chunk = chunks[i];
      console.log(`üîÑ Chunk ${i + 1}/${chunks.length}: ${chunk.length} IDs`);

      const { data, error } = await supabase
        .from(tableName)
        .update({ 
          [updateField]: true,
          validation_status: 'approved',
          reviewed_at: new Date().toISOString()
        })
        .in('id', chunk)
        .select('id');

      if (error) {
        console.error(`‚ùå Erro no chunk ${i + 1}:`, {
          message: error.message,
          details: error.details,
          hint: error.hint,
          code: error.code
        });
        throw new Error(`Erro ao atualizar chunk ${i + 1}/${chunks.length}: ${error.message}`);
      }

      totalUpdated += data?.length || 0;
      console.log(`‚úÖ Chunk ${i + 1} completo: ${data?.length || 0} linhas atualizadas`);
    }

    console.log(`‚úÖ Total atualizado: ${totalUpdated} de ${ids.length} entradas`);

    console.log(`‚úÖ ${entries.length} entradas validadas com sucesso`);

    return new Response(
      JSON.stringify({
        validated: totalUpdated,
        skipped: batchSize - entries.length,
        chunks_processed: chunks.length,
        dictionaryType,
        timestamp: new Date().toISOString()
      }),
      { headers: { ...corsHeaders, 'Content-Type': 'application/json' }, status: 200 }
    );

  } catch (error) {
    console.error('‚ùå Erro na valida√ß√£o em lote:', error);
    const errorMessage = error instanceof Error ? error.message : 'Erro desconhecido';
    return new Response(
      JSON.stringify({ error: errorMessage }),
      { headers: { ...corsHeaders, 'Content-Type': 'application/json' }, status: 500 }
    );
  }
});
