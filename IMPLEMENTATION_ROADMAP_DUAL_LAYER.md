# üöÄ ROADMAP EXECUTIVO: Sistema de Anota√ß√£o Sem√¢ntica Dual-Layer Verso Austral

## üìã √çNDICE
1. [Arquitetura Geral](#1-arquitetura-geral)
2. [Pr√©-Requisitos](#2-pr√©-requisitos)
3. [Sprint 1: Schema Dual-Layer](#sprint-1-schema-dual-layer-1-semana)
4. [Sprint 2: Pipeline DS](#sprint-2-pipeline-ds-2-semanas)
5. [Sprint 3: Sistema de Ins√≠gnias](#sprint-3-sistema-de-ins√≠gnias-2-semanas)
6. [Sprint 4: Validation Dashboard](#sprint-4-validation-dashboard-15-semanas)
7. [Sprint 5: Optimization](#sprint-5-optimization-1-semana)
8. [Sprint 6: Escalabilidade](#sprint-6-escalabilidade-2-semanas)
9. [Cronograma e M√©tricas](#cronograma-e-m√©tricas)

---

## 1. ARQUITETURA GERAL

### Conceito: Dual-Layer System

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    PALAVRA ANOTADA                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Palavra: "xerg√£o"                                          ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ
‚îÇ  CAMADA 1: Dom√≠nio Sem√¢ntico (DS) - UNIVERSAL              ‚îÇ
‚îÇ  ‚îî‚îÄ DS: "EM" (Equipamentos de Montaria)                    ‚îÇ
‚îÇ     ‚îî‚îÄ Compar√°vel entre: RS, MT, Nordeste, Pantanal        ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ
‚îÇ  CAMADA 2: Ins√≠gnias Culturais (IC) - CONTEXTUAL           ‚îÇ
‚îÇ  ‚îî‚îÄ IC Prim√°ria: "Ga√∫cho" (fonte: dialectal_lexicon)       ‚îÇ
‚îÇ  ‚îî‚îÄ IC Secund√°ria: "Platino" (fonte: influencia_platina)   ‚îÇ
‚îÇ     ‚îî‚îÄ Identidade regional/cultural espec√≠fica             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Vantagens da Separa√ß√£o

**Layer 1 (DS Universal):**
- ‚úÖ Comparabilidade estat√≠stica cross-regional
- ‚úÖ Log-likelihood funciona (mesmo DS em corpora diferentes)
- ‚úÖ Escal√°vel para literatura, jornalismo, corpus geral
- ‚úÖ Taxonomia est√°vel (n√£o precisa reestruturar ao adicionar regi√£o)

**Layer 2 (Ins√≠gnias Culturais):**
- ‚úÖ Granularidade cultural preservada
- ‚úÖ Multi-insignia support (`chimarr√£o` = [Ga√∫cho, Platino])
- ‚úÖ Sinergia total com dialectal_lexicon existente (106k entradas)
- ‚úÖ Escalabilidade trivial (nova regi√£o = nova ins√≠gnia)

---

## 2. PR√â-REQUISITOS

### ‚úÖ J√° Implementado no Projeto
- [x] Supabase Lovable Cloud ativo
- [x] dialectal_lexicon populated (106k entradas)
- [x] cultural-insignia.types.ts (InsigniaCultural enum)
- [x] Lovable AI Gateway configurado (Gemini 2.5 Flash/Pro)
- [x] pgvector extension ativa

### ‚ö†Ô∏è Faltando Implementar
- [ ] spaCy pt_core_news_lg integration
- [ ] semantic_tagset com DS Universal (18 dom√≠nios)
- [ ] annotated_corpus.insignias_culturais column
- [ ] semantic_disambiguation_cache table
- [ ] Edge functions de anota√ß√£o

---

## SPRINT 1: Schema Dual-Layer (1 semana)

### üéØ Objetivo
Criar infraestrutura de banco de dados para suportar DS Universal + Ins√≠gnias Culturais

### üì¶ Deliverables

#### 1.1 Migration: Adicionar Ins√≠gnias em annotated_corpus
```sql
-- Adicionar coluna insignias_culturais
ALTER TABLE annotated_corpus 
ADD COLUMN insignias_culturais TEXT[] DEFAULT '{}';

-- √çndice GIN para queries eficientes
CREATE INDEX idx_annotated_corpus_insignias 
ON annotated_corpus USING GIN(insignias_culturais);

-- Coment√°rio descritivo
COMMENT ON COLUMN annotated_corpus.insignias_culturais IS 
'Array de ins√≠gnias culturais (Ga√∫cho, Nordestino, Platino, etc.). Uma palavra pode ter m√∫ltiplas ins√≠gnias.';
```

#### 1.2 Migration: Adicionar Ins√≠gnias em semantic_lexicon
```sql
ALTER TABLE semantic_lexicon 
ADD COLUMN insignias_culturais TEXT[] DEFAULT '{}';

CREATE INDEX idx_semantic_lexicon_insignias 
ON semantic_lexicon USING GIN(insignias_culturais);
```

#### 1.3 Atualizar InsigniaCultural Enum
```typescript
// src/data/types/cultural-insignia.types.ts
export enum InsigniaCultural {
  GAUCHO = 'Ga√∫cho',
  NORDESTINO = 'Nordestino',
  PLATINO = 'Platino',
  INDIGENA = 'Ind√≠gena',
  ALEMAO = 'Alem√£o',
  ITALIANO = 'Italiano',
  CAIPIRA = 'Caipira',
  CARIOCA = 'Carioca',
  AMAZONICO = 'Amaz√¥nico',
  GERAL = 'Geral' // Portugu√™s sem marca regional forte
}
```

#### 1.4 Documentar Taxonomia DS Universal
```markdown
# Taxonomia de Dom√≠nios Sem√¢nticos Universais (18 Dom√≠nios)

## C√≥digo | Nome | Exemplos Multi-Regionais
- NA | Natureza e Paisagem | pampa (RS), sert√£o (NE), cerrado (MT)
- EM | Equipamentos de Montaria | xerg√£o (RS), baixeiro (MT), carona (MT)
- AH | Atividades Humanas | campereada (RS), vaquejada (NE), rodeio (MT)
- SE | Sentimentos e Abstra√ß√µes | saudade (universal), quer√™ncia (RS), sodade (NE)
- OA | Objetos e Artefatos | cuia (RS), gamela (NE)
- BE | Bebidas e Alimenta√ß√£o | chimarr√£o (RS), cacha√ßa (universal)
- MU | M√∫sica e Arte | milonga (RS), forr√≥ (NE), moda de viola (SE)
- VE | Vestu√°rio | bombacha (RS), gib√£o (NE)
- HA | Habita√ß√£o e Constru√ß√µes | galp√£o (RS), casa de taipa (NE)
- AN | Animais | gateado (RS), aboiamento (NE - a√ß√£o), boi (universal)
- FA | Flora | tarum√£ (RS), juazeiro (NE), pau-brasil (SE)
- CO | Corpo Humano | perna, olho, cora√ß√£o (universal)
- TE | Tempo | manh√£s, tarde, noite (universal)
- QU | Qualidades e Estados | lindo, cansado, forte (universal)
- AC | A√ß√µes e Processos | rondar, desgarrar, aquerenciar
- RE | Rela√ß√µes Sociais | patr√£o, pe√£o, prenda (RS), compadre (universal)
- CO | Comunica√ß√£o e Linguagem | verso, copla, cantiga
- FU | Palavras Funcionais | de, o, a, com, em (n√£o recebem DS espec√≠fico)
```

### ‚úÖ Checklist de Valida√ß√£o Sprint 1
- [ ] Migration executada sem erros
- [ ] √çndices GIN criados e funcionando
- [ ] InsigniaCultural enum atualizado com 9-10 valores
- [ ] Documenta√ß√£o de 18 DS com exemplos multi-regionais
- [ ] Exemplos de palavras com DS+IC criados (m√≠nimo 50 exemplos)

---

## SPRINT 2: Pipeline DS - Desambigua√ß√£o de Dom√≠nio Sem√¢ntico (2 semanas)

### üéØ Objetivo
Implementar os 7 m√©todos de desambigua√ß√£o para atribuir DS Universal

### üì¶ Deliverables

#### 2.1 M√©todo 1: POS Tagging
```typescript
// supabase/functions/pos-tagger/index.ts
import { serve } from "https://deno.land/std@0.168.0/http/server.ts";

serve(async (req) => {
  const { text } = await req.json();
  
  // Op√ß√£o A: Chamar spaCy via Python microservice
  const spacyResponse = await fetch('http://python-service/pos-tag', {
    method: 'POST',
    body: JSON.stringify({ text })
  });
  
  const tokens = await spacyResponse.json();
  // tokens: [{ word: "saudade", pos: "NOUN", lemma: "saudade" }, ...]
  
  return new Response(JSON.stringify({ tokens }), {
    headers: { 'Content-Type': 'application/json' }
  });
});
```

#### 2.2 M√©todo 2: Likelihood Ranking (Data-Driven)
```sql
-- Query para calcular likelihood de cada DS para uma palavra
SELECT 
  tagset_primario as ds_codigo,
  COUNT(*) as freq_palavra_ds,
  COUNT(*) * 1.0 / SUM(COUNT(*)) OVER () as likelihood
FROM annotated_corpus
WHERE lema = 'saudade'
GROUP BY tagset_primario
ORDER BY likelihood DESC;

-- Resultado esperado:
-- ds_codigo | freq | likelihood
-- SE        | 45   | 0.85 (85% das vezes "saudade" √© Sentimentos)
-- AC        | 8    | 0.15 (15% das vezes √© A√ß√£o, ex: "matar a saudade")
```

#### 2.3 M√©todo 3: MWE Resolution
```typescript
// supabase/functions/mwe-resolver/index.ts

// Template examples:
const mweTemplates = [
  { pattern: /mate\s+(amargo|doce|quente|gelado)/, ds: 'BE', type: 'fixed_slot' },
  { pattern: /tropa\s+(desgarrada|perdida|reunida)/, ds: 'AN', type: 'fixed_slot' },
  { pattern: /olhos\s+de\s+\w+/, ds: 'CO', type: 'open_slot' } // "olhos de prenda", "olhos de noite"
];

function detectMWE(tokens) {
  const text = tokens.map(t => t.word).join(' ');
  
  for (const template of mweTemplates) {
    const match = text.match(template.pattern);
    if (match) {
      return {
        mwe: match[0],
        ds: template.ds,
        startIndex: match.index,
        endIndex: match.index + match[0].split(' ').length
      };
    }
  }
  
  // Fallback: similarity search para MWEs n√£o-fixos
  // ... (usar embeddings para detectar express√µes similares)
  
  return null;
}
```

#### 2.4 M√©todo 4-7: AI Domain Detection + Contextual Rules + One Sense Per Text
```typescript
// supabase/functions/domain-detector/index.ts
import { createClient } from '@supabase/supabase-js';

serve(async (req) => {
  const { word, context, pos, lemma } = await req.json();
  
  // M√âTODO 5: One Sense Per Text (cache lookup)
  const cached = await supabase
    .from('semantic_disambiguation_cache')
    .select('ds_codigo, confidence')
    .eq('palavra', lemma)
    .eq('context_hash', hashContext(context))
    .single();
  
  if (cached.data) {
    return new Response(JSON.stringify(cached.data));
  }
  
  // M√âTODO 6: Contextual Rules (fallback r√°pido)
  if (lemma === 'saudade') return { ds: 'SE', confidence: 0.95, source: 'rule' };
  if (lemma === 'mate' && context.includes('amargo')) return { ds: 'BE', confidence: 0.92, source: 'rule' };
  
  // M√âTODO 4: AI Domain Detection (Gemini Flash)
  const geminiResponse = await fetch('https://ai.gateway.lovable.dev/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${Deno.env.get('LOVABLE_API_KEY')}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      model: 'google/gemini-2.5-flash',
      messages: [{
        role: 'system',
        content: `Voc√™ √© um classificador sem√¢ntico especializado em portugu√™s brasileiro.
        
Dom√≠nios dispon√≠veis:
NA (Natureza), EM (Equipamentos), AH (Atividades), SE (Sentimentos), OA (Objetos), 
BE (Bebidas/Alimenta√ß√£o), MU (M√∫sica), VE (Vestu√°rio), HA (Habita√ß√£o), AN (Animais), 
FA (Flora), CO (Corpo), TE (Tempo), QU (Qualidades), AC (A√ß√µes), RE (Rela√ß√µes), 
CM (Comunica√ß√£o), FU (Funcional)

Responda APENAS com JSON: {"ds": "XX", "confidence": 0.XX, "reasoning": "..."}` 
      }, {
        role: 'user',
        content: `Palavra: "${word}" (lema: "${lemma}")
POS: ${pos}
Contexto: "${context}"

Qual dom√≠nio sem√¢ntico?`
      }],
      response_format: { type: 'json_object' }
    })
  });
  
  const result = await geminiResponse.json();
  const dsData = JSON.parse(result.choices[0].message.content);
  
  // Cache resultado
  await supabase.from('semantic_disambiguation_cache').insert({
    palavra: lemma,
    context_hash: hashContext(context),
    ds_codigo: dsData.ds,
    confidence: dsData.confidence,
    reasoning: dsData.reasoning
  });
  
  return new Response(JSON.stringify(dsData));
});
```

### ‚úÖ Checklist de Valida√ß√£o Sprint 2
- [ ] spaCy integration funcionando (POS tagging retorna tags corretas)
- [ ] Likelihood ranking calculado para top 100 palavras do corpus
- [ ] MWE resolver detecta pelo menos 50 express√µes ga√∫chas
- [ ] Domain detector (Gemini) testado com 100 palavras (accuracy > 90%)
- [ ] Cache funcionando (2¬™ chamada retorna cached result < 10ms)
- [ ] Unit tests passando (cobertura > 80%)

---

## SPRINT 3: Sistema de Ins√≠gnias Culturais (2 semanas)

### üéØ Objetivo
Implementar pipeline de atribui√ß√£o de Ins√≠gnias Culturais (Layer 2)

### üì¶ Deliverables

#### 3.1 Primary Insignia Rules (Regras Determin√≠sticas)
```typescript
// src/lib/insigniaAttribution.ts

export async function getPrimaryInsignia(palavra: string): Promise<InsigniaAttribution | null> {
  // Lookup em dialectal_lexicon
  const { data: entry } = await supabase
    .from('dialectal_lexicon')
    .select('origem_regionalista, influencia_platina, tipo_dicionario')
    .eq('verbete_normalizado', normalizarPalavra(palavra))
    .single();
  
  if (!entry) return null;
  
  // Regra 1: origem_regionalista
  if (entry.origem_regionalista?.includes('Ga√∫cho')) {
    return {
      primaryInsignia: InsigniaCultural.GAUCHO,
      secondaryInsignias: entry.influencia_platina ? [InsigniaCultural.PLATINO] : [],
      confidence: 0.95,
      source: 'dialectal_lexicon.origem_regionalista'
    };
  }
  
  // Regra 2: tipo_dicionario implica regi√£o
  if (entry.tipo_dicionario === 'nunes' || entry.tipo_dicionario === 'ufrgs') {
    return {
      primaryInsignia: InsigniaCultural.GAUCHO,
      secondaryInsignias: [],
      confidence: 0.90,
      source: 'dialectal_lexicon.tipo_dicionario'
    };
  }
  
  return null;
}
```

#### 3.2 Contextual Insignia (Corpus-Type Rule)
```typescript
export async function getContextualInsignia(songId: string): Promise<InsigniaCultural | null> {
  // Query: song ‚Üí artist ‚Üí corpus ‚Üí normalized_name
  const { data: song } = await supabase
    .from('songs')
    .select('artist:artists(corpus:corpora(normalized_name))')
    .eq('id', songId)
    .single();
  
  const corpusName = song?.artist?.corpus?.normalized_name;
  
  const corpusTypeMap = {
    'gaucho': InsigniaCultural.GAUCHO,
    'nordestino': InsigniaCultural.NORDESTINO,
    'platino': InsigniaCultural.PLATINO
    // ... expandir conforme novos corpus_types
  };
  
  return corpusTypeMap[corpusName] || InsigniaCultural.GERAL;
}
```

#### 3.3 Gemini Insignia Inference
```typescript
// supabase/functions/insignia-inferencer/index.ts

const INSIGNIA_PROMPT = `Analise a palavra "{palavra}" no contexto cultural brasileiro.

Defini√ß√£o: {defini√ß√£o do dialectal_lexicon se dispon√≠vel}
Contextos culturais: {contextos_culturais se dispon√≠vel}
Dom√≠nio Sem√¢ntico: {DS j√° atribu√≠do}
Senten√ßa: "{contexto}"

Retorne um array JSON com ins√≠gnias culturais aplic√°veis:

Ins√≠gnias dispon√≠veis:
- "Ga√∫cho": espec√≠fico da cultura ga√∫cha/rio-grandense (mate, galp√£o, bombacha, xerg√£o, CTG)
- "Platino": influ√™ncia uruguaia/argentina (chimarr√£o, pulperia, che, pampa compartilhado)
- "Ind√≠gena": origem tupi-guarani ou povos origin√°rios (capim, taquara, mandioca)
- "Alem√£o": imigra√ß√£o alem√£ no Sul (schimia, cuca, kerb)
- "Italiano": imigra√ß√£o italiana no Sul (polenta, cantina, nona)
- "Nordestino": espec√≠fico do nordeste (forr√≥, bai√£o, vaqueiro, aboio)
- "Caipira": cultura caipira/sertaneja (viola, moda, sert√£o interior)
- "Carioca": espec√≠fico do Rio de Janeiro (samba, favela, malandro)
- "Amaz√¥nico": regi√£o amaz√¥nica (a√ßa√≠, tacac√°, pirarucu)
- "Geral": portugu√™s geral sem marca regional forte

IMPORTANTE: 
- Uma palavra pode ter m√∫ltiplas ins√≠gnias (ex: "chimarr√£o" = ["Ga√∫cho", "Platino"])
- Se n√£o h√° marca regional clara, retorne ["Geral"]
- Considere etimologia e uso cultural, n√£o apenas geografia

Responda APENAS com array JSON: ["Ins√≠gnia1", "Ins√≠gnia2"]`;

serve(async (req) => {
  const { palavra, definicao, contextos_culturais, ds_codigo, context } = await req.json();
  
  const prompt = INSIGNIA_PROMPT
    .replace('{palavra}', palavra)
    .replace('{defini√ß√£o do dialectal_lexicon se dispon√≠vel}', definicao || 'n√£o dispon√≠vel')
    .replace('{contextos_culturais se dispon√≠vel}', JSON.stringify(contextos_culturais) || 'n√£o dispon√≠vel')
    .replace('{DS j√° atribu√≠do}', ds_codigo || 'n√£o atribu√≠do ainda')
    .replace('{contexto}', context);
  
  const geminiResponse = await fetch('https://ai.gateway.lovable.dev/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${Deno.env.get('LOVABLE_API_KEY')}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      model: 'google/gemini-2.5-flash',
      messages: [{ role: 'user', content: prompt }]
    })
  });
  
  const result = await geminiResponse.json();
  const insigniasText = result.choices[0].message.content;
  const insignias = JSON.parse(insigniasText.match(/\[.*\]/)[0]); // Extract JSON array
  
  // Validar ins√≠gnias contra enum
  const validInsignias = insignias.filter(i => Object.values(InsigniaCultural).includes(i));
  
  return new Response(JSON.stringify({ 
    insignias: validInsignias, 
    confidence: 0.85,
    source: 'gemini_inference' 
  }));
});
```

#### 3.4 Orquestrador: Pipeline Completo Dual-Layer
```typescript
// supabase/functions/annotate-semantic-dual-layer/index.ts

serve(async (req) => {
  const { songId, texto } = await req.json();
  
  // 1. POS Tagging
  const { data: posResult } = await supabase.functions.invoke('pos-tagger', { body: { text: texto } });
  const tokens = posResult.tokens;
  
  // 2. MWE Resolution
  const mwes = await resolveMWEs(tokens);
  
  // 3. Para cada palavra/MWE:
  const annotatedWords = [];
  
  for (const token of tokens) {
    // Skip se parte de MWE
    if (mwes.some(mwe => mwe.includes(token.index))) continue;
    
    // LAYER 1: Domain Semantic (DS)
    const ds = await getDomainSemantic(token, context);
    
    // LAYER 2: Cultural Insignias (IC)
    const primaryIC = await getPrimaryInsignia(token.lemma);
    const contextualIC = await getContextualInsignia(songId);
    const geminiIC = primaryIC ? null : await getGeminiInsignia(token, ds);
    
    const insignias = [
      primaryIC?.primaryInsignia,
      ...(primaryIC?.secondaryInsignias || []),
      contextualIC,
      ...(geminiIC?.insignias || [])
    ].filter(Boolean);
    
    annotatedWords.push({
      palavra: token.word,
      lema: token.lemma,
      pos: token.pos,
      tagset_primario: ds.codigo,
      confianca_ds: ds.confidence,
      insignias_culturais: [...new Set(insignias)], // Remove duplicates
      confianca_ic: primaryIC?.confidence || geminiIC?.confidence || 0.7
    });
  }
  
  // 4. Salvar em annotated_corpus
  await supabase.from('annotated_corpus').insert(
    annotatedWords.map(w => ({ ...w, job_id: jobId }))
  );
  
  return new Response(JSON.stringify({ 
    success: true, 
    annotated: annotatedWords.length 
  }));
});
```

### ‚úÖ Checklist de Valida√ß√£o Sprint 3
- [ ] Insignia rules detectam 70% das palavras dialetais automaticamente
- [ ] Gemini inference funciona para palavras n√£o catalogadas
- [ ] Pipeline dual-layer anota 1 m√∫sica completa em < 5s
- [ ] insignias_culturais array populado corretamente (sem duplicatas)
- [ ] Testado com 50 m√∫sicas: verificar qualidade manual das ins√≠gnias

---

## SPRINT 4: Validation Dashboard Dual-Layer (1.5 semanas)

### üéØ Objetivo
Interface para valida√ß√£o humana separada de DS e IC

### üì¶ Deliverables

#### 4.1 UI de Valida√ß√£o Dual-Layer
```tsx
// src/components/validation/DualLayerValidationPanel.tsx

export const DualLayerValidationPanel = () => {
  return (
    <div className="grid grid-cols-2 gap-4">
      {/* Coluna Esquerda: Valida√ß√£o DS */}
      <Card>
        <CardHeader>Valida√ß√£o de Dom√≠nio Sem√¢ntico (DS)</CardHeader>
        <CardContent>
          <div>Palavra: <strong>{word.palavra}</strong></div>
          <div>DS Atual: <Badge>{word.tagset_primario}</Badge></div>
          <div>Confian√ßa: {word.confianca_ds * 100}%</div>
          
          <Select 
            value={correctedDS} 
            onChange={setCorrectedDS}
            options={DS_OPTIONS} // 18 dom√≠nios universais
          />
          
          <Textarea 
            placeholder="Justificativa da corre√ß√£o..."
            value={dsJustification}
          />
          
          <Button onClick={handleSaveDSCorrection}>
            Corrigir DS
          </Button>
        </CardContent>
      </Card>
      
      {/* Coluna Direita: Valida√ß√£o Ins√≠gnias */}
      <Card>
        <CardHeader>Valida√ß√£o de Ins√≠gnias Culturais (IC)</CardHeader>
        <CardContent>
          <div>Palavra: <strong>{word.palavra}</strong></div>
          <div>Ins√≠gnias Atuais: 
            {word.insignias_culturais.map(ic => <Badge key={ic}>{ic}</Badge>)}
          </div>
          <div>Confian√ßa IC: {word.confianca_ic * 100}%</div>
          
          <MultiSelect 
            value={correctedInsignias} 
            onChange={setCorrectedInsignias}
            options={INSIGNIA_OPTIONS} // 10 ins√≠gnias
          />
          
          <Textarea 
            placeholder="Justificativa da corre√ß√£o de ins√≠gnias..."
            value={icJustification}
          />
          
          <Button onClick={handleSaveICCorrection}>
            Corrigir Ins√≠gnias
          </Button>
        </CardContent>
      </Card>
    </div>
  );
};
```

#### 4.2 Feedback Loop: Auto-Update de Rankings
```typescript
// Quando usu√°rio corrige DS de uma palavra:
async function handleDSCorrection(wordId, newDS, justification) {
  // 1. Salvar corre√ß√£o
  await supabase.from('human_validations').insert({
    palavra: word.palavra,
    tagset_original: word.tagset_primario,
    tagset_corrigido: newDS,
    justificativa: justification,
    user_id: userId
  });
  
  // 2. Auto-update: recalcular likelihood ranking
  // Se muitas pessoas corrigem "saudade" de AC ‚Üí SE, o likelihood de SE aumenta
  const corrections = await supabase
    .from('human_validations')
    .select('tagset_corrigido')
    .eq('palavra', word.lema)
    .eq('aplicado', true);
  
  // Recalcular frequ√™ncia corrigida
  const newLikelihood = calculateLikelihoodWithCorrections(word.lema, corrections);
  
  // Atualizar semantic_lexicon
  await supabase
    .from('semantic_lexicon')
    .update({ likelihood_ranking: newLikelihood })
    .eq('palavra', word.lema);
}
```

### ‚úÖ Checklist de Valida√ß√£o Sprint 4
- [ ] Interface permite corrigir DS e IC independentemente
- [ ] Justificativas s√£o obrigat√≥rias (campo required)
- [ ] Feedback loop atualiza likelihood rankings automaticamente
- [ ] Kappa calculado entre 2 anotadores > 0.80 (substantial agreement)
- [ ] Exporta√ß√£o CSV funciona com colunas: palavra | lema | DS | IC[] | confidences
- [ ] Dashboard de qualidade mostra Precision/Recall DS e Accuracy IC

---

## SPRINT 5: Optimization & Scale (1 semana)

### üéØ Objetivo
Batch processing, vector search, performance monitoring

### üì¶ Deliverables

#### 5.1 Batch Processing Edge Function
```typescript
// supabase/functions/batch-annotate-songs/index.ts

serve(async (req) => {
  const { songIds } = await req.json(); // Array de at√© 50 IDs
  
  // Processar em paralelo com p-limit
  const limit = pLimit(10); // 10 simult√¢neas
  
  const results = await Promise.all(
    songIds.map(songId => 
      limit(() => annotateSong(songId))
    )
  );
  
  return new Response(JSON.stringify({ 
    processed: results.length,
    success: results.filter(r => r.success).length,
    failed: results.filter(r => !r.success).length
  }));
});
```

#### 5.2 Vector Search para OOV Handling
```sql
-- Adicionar embedding column em semantic_lexicon
ALTER TABLE semantic_lexicon 
ADD COLUMN embedding vector(1536);

-- Criar √≠ndice HNSW para similarity search
CREATE INDEX idx_semantic_lexicon_embedding 
ON semantic_lexicon 
USING hnsw (embedding vector_cosine_ops);

-- Query para encontrar palavra similar:
SELECT palavra, tagset_primario, insignias_culturais,
       1 - (embedding <=> query_embedding) as similarity
FROM semantic_lexicon
WHERE 1 - (embedding <=> query_embedding) > 0.85
ORDER BY similarity DESC
LIMIT 5;
```

### ‚úÖ Checklist de Valida√ß√£o Sprint 5
- [ ] Batch processing anota 50 m√∫sicas em < 3 minutos
- [ ] Cache hit rate > 85% ap√≥s primeira passada
- [ ] Vector search retorna palavras similares em < 200ms
- [ ] Performance monitoring implementado (logs de lat√™ncia)
- [ ] Custo m√©dio por m√∫sica < $0.01

---

## SPRINT 6: Escalabilidade Multi-Regional (2 semanas)

### üéØ Objetivo
Suportar m√∫ltiplos regionalismos e corpus liter√°rio

### üì¶ Deliverables

#### 6.1 Adicionar Novos Corpus Types
```sql
-- Adicionar corpus nordestino
INSERT INTO corpora (name, normalized_name, description, is_system)
VALUES (
  'M√∫sica Nordestina',
  'nordestino',
  'Corpus de m√∫sica nordestina: forr√≥, bai√£o, xote, etc.',
  true
);

-- Importar m√∫sicas nordestinas (exemplo)
-- ... (upload Excel / API import)
```

#### 6.2 Expandir Dialectal Lexicon com Termos Nordestinos
```typescript
// Script de importa√ß√£o de dicion√°rio nordestino
const nordestineTerms = [
  { verbete: 'forr√≥', ds: 'MU', insignias: ['Nordestino'] },
  { verbete: 'bai√£o', ds: 'MU', insignias: ['Nordestino'] },
  { verbete: 'aboio', ds: 'AC', insignias: ['Nordestino'] },
  { verbete: 'vaquejada', ds: 'AH', insignias: ['Nordestino'] }
  // ... 500+ termos
];

await supabase.from('dialectal_lexicon').insert(
  nordestineTerms.map(term => ({
    verbete: term.verbete,
    verbete_normalizado: normalizarPalavra(term.verbete),
    origem_regionalista: ['Nordestino'],
    tipo_dicionario: 'nordestino_lexicon',
    // ... outros campos
  }))
);
```

#### 6.3 An√°lise Comparativa Cross-Regional
```typescript
// src/pages/ComparativeAnalysis.tsx

export const ComparativeAnalysisPage = () => {
  // Query: distribui√ß√£o de DS em corpus ga√∫cho
  const { data: gauchoStats } = useQuery(['ds-distribution', 'gaucho'], async () => {
    const { data } = await supabase.rpc('calculate_ds_distribution', { corpus_type: 'gaucho' });
    return data;
  });
  
  // Query: distribui√ß√£o de DS em corpus nordestino
  const { data: nordestinoStats } = useQuery(['ds-distribution', 'nordestino'], async () => {
    const { data } = await supabase.rpc('calculate_ds_distribution', { corpus_type: 'nordestino' });
    return data;
  });
  
  return (
    <div>
      <h1>An√°lise Comparativa: Ga√∫cho vs. Nordestino</h1>
      
      <ComparisonChart 
        data={[
          { domain: 'Natureza', gaucho: 22.2, nordestino: 7.2 },
          { domain: 'Cultura Regional', gaucho: 23.9, nordestino: 15.1 },
          // ...
        ]} 
      />
      
      <Table>
        <thead>
          <tr>
            <th>Dom√≠nio Sem√¢ntico (DS)</th>
            <th>Ga√∫cho (%)</th>
            <th>Nordestino (%)</th>
            <th>An√°lise</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>Natureza e Paisagem (NA)</td>
            <td>22.2%</td>
            <td>7.2%</td>
            <td className="text-green-500">SUPER-REPRESENTADO no Ga√∫cho</td>
          </tr>
          {/* ... */}
        </tbody>
      </Table>
    </div>
  );
};
```

### ‚úÖ Checklist de Valida√ß√£o Sprint 6
- [ ] Corpus nordestino importado e processado (500 m√∫sicas test)
- [ ] Ins√≠gnias nordestinas atribu√≠das corretamente
- [ ] An√°lise comparativa mostra diferen√ßas estat√≠sticas claras
- [ ] Pipeline funciona para literatura (teste com 50 p√°ginas de prosa)
- [ ] API p√∫blica permite POST /annotate com custom corpus_type

---

## CRONOGRAMA E M√âTRICAS

### Timeline Geral
```
Sprint 1: Schema Dual-Layer           [1 sem]  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë
Sprint 2: Pipeline DS                 [2 sem]  ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë
Sprint 3: Sistema de Ins√≠gnias        [2 sem]  ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
Sprint 4: Validation Dashboard        [1.5sem] ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
Sprint 5: Optimization                [1 sem]  ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñà‚ñà‚ñà‚ñà
Sprint 6: Escalabilidade Multi-Region [2 sem]  ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
                                      ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
TOTAL: 9.5 semanas (~2.5 meses)
```

### M√©tricas de Sucesso

| M√©trica | Target | Como Medir |
|---------|--------|------------|
| **DS Accuracy** | ‚â• 94% | Comparar anota√ß√µes autom√°ticas vs. gold standard (500 m√∫sicas) |
| **IC Accuracy** | ‚â• 92% | Valida√ß√£o manual de ins√≠gnias atribu√≠das |
| **Coverage Rate** | ‚â• 95% | % de palavras que recebem DS (n√£o OOV) |
| **Processing Speed** | < 5s/m√∫sica | Timer em edge function (200 palavras t√≠picas) |
| **Cost per Song** | < $0.01 | Gemini API usage tracking (cache hit rate 85%+) |
| **Inter-Annotator Agreement (Kappa)** | ‚â• 0.80 | Calcular Kappa entre 2 linguistas em 200 m√∫sicas |

### Pontos Cr√≠ticos de Decis√£o

#### Decis√£o 1: spaCy Integration
**Op√ß√µes:**
- A) Python microservice (Flask/FastAPI) chamado via HTTP
- B) Deno FFI para chamar Python directly
- C) JavaScript POS tagger (compromise_nlp) - menos preciso mas mais simples

**Recomenda√ß√£o:** Op√ß√£o A (microservice) por performance e facilidade de manuten√ß√£o.

#### Decis√£o 2: Gemini Flash vs. Pro para DS
**An√°lise:**
- Flash: $0.00001/token, lat√™ncia 800ms, accuracy ~88%
- Pro: $0.0001/token, lat√™ncia 1500ms, accuracy ~95%

**Recomenda√ß√£o:** Usar Flash para DS (economy) + Pro apenas para casos amb√≠guos (confidence < 70%)

#### Decis√£o 3: Embeddings Dimension (1536 vs 384)
**Trade-off:**
- 1536 dims: 6KB/palavra, accuracy 95% similarity
- 384 dims: 1.5KB/palavra, accuracy 92% similarity

**Recomenda√ß√£o:** Iniciar com 1536 (Gemini native), comprimir para 384 se storage/performance se tornar problema

---

## PR√ìXIMOS PASSOS IMEDIATOS

### A√ß√£o 1: Executar Sprint 1 - Migrations (2 horas)
1. Criar migration para adicionar `insignias_culturais TEXT[]` em `annotated_corpus`
2. Criar migration para adicionar `insignias_culturais TEXT[]` em `semantic_lexicon`
3. Atualizar `InsigniaCultural` enum em `cultural-insignia.types.ts`
4. Validar migrations executadas corretamente
5. Criar 50 exemplos de palavras com DS+IC para documenta√ß√£o

### A√ß√£o 2: Documentar Taxonomia DS Universal (4 horas)
6. Criar arquivo `SEMANTIC_TAXONOMY_UNIVERSAL.md`
7. Definir 18 dom√≠nios com exemplos multi-regionais
8. Para cada DS, listar: c√≥digo, nome, descri√ß√£o, exemplos (ga√∫cho, nordestino, geral)
9. Criar tabela comparativa: palavra | DS | IC_Ga√∫cho | IC_Nordestino

### A√ß√£o 3: Proof of Concept - POS Tagger (6 horas)
10. Decidir: Python microservice ou JavaScript compromise_nlp
11. Implementar edge function `pos-tagger`
12. Testar com 10 m√∫sicas ga√∫chas
13. Validar: accuracy POS > 90% em texto po√©tico/regional

### A√ß√£o 4: Implementar Insignia Rules (4 horas)
14. Criar `src/lib/insigniaAttribution.ts` com regras determin√≠sticas
15. Implementar `getPrimaryInsignia()` (dialectal_lexicon lookup)
16. Implementar `getContextualInsignia()` (corpus_type lookup)
17. Testar com 100 palavras dialetais conhecidas

---

## RISCOS E MITIGA√á√ïES

| Risco | Probabilidade | Impacto | Mitiga√ß√£o |
|-------|---------------|---------|-----------|
| spaCy integration complexa | Alta | Alto | Iniciar com compromise_nlp (JS), migrar para spaCy se necess√°rio |
| Gemini quota exceeded | M√©dia | Alto | Cache agressivo (85% hit rate) + fallback para rules |
| Ins√≠gnias amb√≠guas (palavra em m√∫ltiplas regi√µes) | Alta | M√©dio | Multi-insignia support + confidence scoring |
| DS taxonomy n√£o cobre casos raros | M√©dia | M√©dio | Categoria "OT" (Outros) + AI classification para expandir |
| Performance < 5s/m√∫sica | Baixa | Alto | Batch processing + otimiza√ß√£o de queries + √≠ndices adequados |

---

## CRIT√âRIOS DE SUCESSO FINAL

### Para considerar o sistema "production-ready":

‚úÖ **Funcionalidade Core:**
- [ ] Pipeline dual-layer anota 1000 m√∫sicas com DS + IC
- [ ] Accuracy DS ‚â• 94% validado contra gold standard
- [ ] Accuracy IC ‚â• 92% validado contra gold standard
- [ ] Coverage ‚â• 95% (menos de 5% de palavras ficam como OOV)

‚úÖ **Performance:**
- [ ] Processamento < 5s por m√∫sica (200 palavras t√≠picas)
- [ ] Cache hit rate > 85% ap√≥s primeira passada
- [ ] Batch processing: 50 m√∫sicas em < 3 minutos

‚úÖ **Custo:**
- [ ] Custo m√©dio < $0.01 por m√∫sica
- [ ] Gemini API usage tracking implementado
- [ ] Budget alert se custo > $10/dia

‚úÖ **Escalabilidade:**
- [ ] Pipeline funciona para corpus nordestino (teste com 500 m√∫sicas)
- [ ] Compara√ß√£o cross-regional funciona (Ga√∫cho vs. Nordestino)
- [ ] Adapta√ß√£o para literatura testada (50 p√°ginas de prosa)

‚úÖ **Qualidade:**
- [ ] Inter-annotator agreement (Kappa) > 0.80
- [ ] Feedback loop funciona (corre√ß√µes atualizam rankings)
- [ ] Documenta√ß√£o completa (taxonomia + regras + exemplos)

---

## CONTATO E SUPORTE

**Documento criado:** 2025-01-15  
**Vers√£o:** 1.0 (Dual-Layer Architecture)  
**Pr√≥xima revis√£o:** Ap√≥s Sprint 3 (valida√ß√£o da arquitetura)

**Para d√∫vidas ou sugest√µes:**  
Consultar documenta√ß√£o t√©cnica completa em `src/data/developer-logs/usas-methodology.ts`

---

**FIM DO ROADMAP EXECUTIVO**
